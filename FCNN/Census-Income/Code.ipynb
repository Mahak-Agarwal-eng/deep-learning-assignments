{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "SYAAkunGM4BY"
      },
      "outputs": [],
      "source": [
        "import  numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\",\"education_num\",\"marital status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital_gain\",\"capital_loss\",\"hrs_per_week\",\"native_country\",\"income\"]\n",
        "df = pd.read_csv(\"adult.data\", header=None, names=columns)\n",
        "df.to_csv(\"adult.csv\", index=False)"
      ],
      "metadata": {
        "id": "FXHTuhruNA1N"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "collapsed": true,
        "id": "c3dO2hPDPZXE",
        "outputId": "6581e5de-6cad-4c1f-e703-c24e24289e10"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age          workclass  fnlwgt   education  education_num  \\\n",
              "0   39          State-gov   77516   Bachelors             13   \n",
              "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
              "2   38            Private  215646     HS-grad              9   \n",
              "3   53            Private  234721        11th              7   \n",
              "4   28            Private  338409   Bachelors             13   \n",
              "\n",
              "        marital status          occupation    relationship    race      sex  \\\n",
              "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
              "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
              "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
              "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
              "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
              "\n",
              "   capital_gain  capital_loss  hrs_per_week  native_country  income  \n",
              "0          2174             0            40   United-States   <=50K  \n",
              "1             0             0            13   United-States   <=50K  \n",
              "2             0             0            40   United-States   <=50K  \n",
              "3             0             0            40   United-States   <=50K  \n",
              "4             0             0            40            Cuba   <=50K  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba9b1c74-bde2-45fd-b838-1779f1d0ff4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hrs_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba9b1c74-bde2-45fd-b838-1779f1d0ff4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba9b1c74-bde2-45fd-b838-1779f1d0ff4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba9b1c74-bde2-45fd-b838-1779f1d0ff4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 32561,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 17,\n        \"max\": 90,\n        \"num_unique_values\": 73,\n        \"samples\": [\n          28,\n          73,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"workclass\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \" Without-pay\",\n          \" Self-emp-not-inc\",\n          \" ?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fnlwgt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105549,\n        \"min\": 12285,\n        \"max\": 1484705,\n        \"num_unique_values\": 21648,\n        \"samples\": [\n          128485,\n          469907,\n          235951\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \" Bachelors\",\n          \" HS-grad\",\n          \" Some-college\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 16,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          13,\n          9,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \" Never-married\",\n          \" Married-civ-spouse\",\n          \" Married-AF-spouse\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occupation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \" Machine-op-inspct\",\n          \" ?\",\n          \" Adm-clerical\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relationship\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \" Not-in-family\",\n          \" Husband\",\n          \" Other-relative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"race\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \" Black\",\n          \" Other\",\n          \" Asian-Pac-Islander\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" Female\",\n          \" Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital_gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7385,\n        \"min\": 0,\n        \"max\": 99999,\n        \"num_unique_values\": 119,\n        \"samples\": [\n          3781,\n          15831\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 402,\n        \"min\": 0,\n        \"max\": 4356,\n        \"num_unique_values\": 92,\n        \"samples\": [\n          419,\n          2051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hrs_per_week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 1,\n        \"max\": 99,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          6,\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"native_country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 42,\n        \"samples\": [\n          \" El-Salvador\",\n          \" Philippines\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"income\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" >50K\",\n          \" <=50K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.replace(\" ?\", pd.NA)"
      ],
      "metadata": {
        "id": "29ASz9yCTE8U"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = df.select_dtypes(include=\"object\").columns\n",
        "print(cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgGGhGldT00r",
        "outputId": "be24cd87-497a-490a-ef68-b6ecb60abaf6"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['workclass', 'education', 'marital status', 'occupation',\n",
            "       'relationship', 'race', 'sex', 'native_country', 'income'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df,columns=cols,drop_first=True)\n",
        "df = df.astype(int)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "collapsed": true,
        "id": "rDBcgC6nT5Gq",
        "outputId": "6a5a5b0d-926c-4a16-bfe1-e180a0045649"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       age  fnlwgt  education_num  capital_gain  capital_loss  hrs_per_week  \\\n",
              "0       39   77516             13          2174             0            40   \n",
              "1       50   83311             13             0             0            13   \n",
              "2       38  215646              9             0             0            40   \n",
              "3       53  234721              7             0             0            40   \n",
              "4       28  338409             13             0             0            40   \n",
              "...    ...     ...            ...           ...           ...           ...   \n",
              "32556   27  257302             12             0             0            38   \n",
              "32557   40  154374              9             0             0            40   \n",
              "32558   58  151910              9             0             0            40   \n",
              "32559   22  201490              9             0             0            20   \n",
              "32560   52  287927              9         15024             0            40   \n",
              "\n",
              "       workclass_ Local-gov  workclass_ Never-worked  workclass_ Private  \\\n",
              "0                         0                        0                   0   \n",
              "1                         0                        0                   0   \n",
              "2                         0                        0                   1   \n",
              "3                         0                        0                   1   \n",
              "4                         0                        0                   1   \n",
              "...                     ...                      ...                 ...   \n",
              "32556                     0                        0                   1   \n",
              "32557                     0                        0                   1   \n",
              "32558                     0                        0                   1   \n",
              "32559                     0                        0                   1   \n",
              "32560                     0                        0                   0   \n",
              "\n",
              "       workclass_ Self-emp-inc  ...  native_country_ Puerto-Rico  \\\n",
              "0                            0  ...                            0   \n",
              "1                            0  ...                            0   \n",
              "2                            0  ...                            0   \n",
              "3                            0  ...                            0   \n",
              "4                            0  ...                            0   \n",
              "...                        ...  ...                          ...   \n",
              "32556                        0  ...                            0   \n",
              "32557                        0  ...                            0   \n",
              "32558                        0  ...                            0   \n",
              "32559                        0  ...                            0   \n",
              "32560                        1  ...                            0   \n",
              "\n",
              "       native_country_ Scotland  native_country_ South  \\\n",
              "0                             0                      0   \n",
              "1                             0                      0   \n",
              "2                             0                      0   \n",
              "3                             0                      0   \n",
              "4                             0                      0   \n",
              "...                         ...                    ...   \n",
              "32556                         0                      0   \n",
              "32557                         0                      0   \n",
              "32558                         0                      0   \n",
              "32559                         0                      0   \n",
              "32560                         0                      0   \n",
              "\n",
              "       native_country_ Taiwan  native_country_ Thailand  \\\n",
              "0                           0                         0   \n",
              "1                           0                         0   \n",
              "2                           0                         0   \n",
              "3                           0                         0   \n",
              "4                           0                         0   \n",
              "...                       ...                       ...   \n",
              "32556                       0                         0   \n",
              "32557                       0                         0   \n",
              "32558                       0                         0   \n",
              "32559                       0                         0   \n",
              "32560                       0                         0   \n",
              "\n",
              "       native_country_ Trinadad&Tobago  native_country_ United-States  \\\n",
              "0                                    0                              1   \n",
              "1                                    0                              1   \n",
              "2                                    0                              1   \n",
              "3                                    0                              1   \n",
              "4                                    0                              0   \n",
              "...                                ...                            ...   \n",
              "32556                                0                              1   \n",
              "32557                                0                              1   \n",
              "32558                                0                              1   \n",
              "32559                                0                              1   \n",
              "32560                                0                              1   \n",
              "\n",
              "       native_country_ Vietnam  native_country_ Yugoslavia  income_ >50K  \n",
              "0                            0                           0             0  \n",
              "1                            0                           0             0  \n",
              "2                            0                           0             0  \n",
              "3                            0                           0             0  \n",
              "4                            0                           0             0  \n",
              "...                        ...                         ...           ...  \n",
              "32556                        0                           0             0  \n",
              "32557                        0                           0             1  \n",
              "32558                        0                           0             0  \n",
              "32559                        0                           0             0  \n",
              "32560                        0                           0             1  \n",
              "\n",
              "[32561 rows x 98 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8852bd55-83be-4d33-9884-ada48079a061\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education_num</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hrs_per_week</th>\n",
              "      <th>workclass_ Local-gov</th>\n",
              "      <th>workclass_ Never-worked</th>\n",
              "      <th>workclass_ Private</th>\n",
              "      <th>workclass_ Self-emp-inc</th>\n",
              "      <th>...</th>\n",
              "      <th>native_country_ Puerto-Rico</th>\n",
              "      <th>native_country_ Scotland</th>\n",
              "      <th>native_country_ South</th>\n",
              "      <th>native_country_ Taiwan</th>\n",
              "      <th>native_country_ Thailand</th>\n",
              "      <th>native_country_ Trinadad&amp;Tobago</th>\n",
              "      <th>native_country_ United-States</th>\n",
              "      <th>native_country_ Vietnam</th>\n",
              "      <th>native_country_ Yugoslavia</th>\n",
              "      <th>income_ &gt;50K</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>77516</td>\n",
              "      <td>13</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>83311</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>215646</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>234721</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>338409</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32556</th>\n",
              "      <td>27</td>\n",
              "      <td>257302</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32557</th>\n",
              "      <td>40</td>\n",
              "      <td>154374</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32558</th>\n",
              "      <td>58</td>\n",
              "      <td>151910</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32559</th>\n",
              "      <td>22</td>\n",
              "      <td>201490</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32560</th>\n",
              "      <td>52</td>\n",
              "      <td>287927</td>\n",
              "      <td>9</td>\n",
              "      <td>15024</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32561 rows Ã— 98 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8852bd55-83be-4d33-9884-ada48079a061')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8852bd55-83be-4d33-9884-ada48079a061 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8852bd55-83be-4d33-9884-ada48079a061');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_1d9dbcdc-230b-4a2c-a4ac-957210bb4fa0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1d9dbcdc-230b-4a2c-a4ac-957210bb4fa0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TcMYRiqrUknP",
        "outputId": "a7a0cf87-d3b2-407a-88f2-b00ed78587a9"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32561, 98)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df.drop(columns=[\"income_ >50K\"])\n",
        "y_train=df[\"income_ >50K\"]"
      ],
      "metadata": {
        "id": "uXk1_jYPbLLL"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytb884CXhwp5",
        "outputId": "1d2d368e-2149-41f8-cf0c-cd7dc388071a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32561, 97)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df2 = pd.read_csv(\"adult.test\", header=None, names=columns,skiprows=1)\n",
        "df2.to_csv(\"adult_test.csv\", index=False)\n",
        "df2 = df2.replace(\" ?\", pd.NA)\n",
        "\n",
        "cols2= df2.select_dtypes(include=\"object\").columns\n",
        "print(cols2)\n",
        "\n",
        "df2 = pd.get_dummies(df2,columns=cols2,drop_first=True)\n",
        "df2.astype(int)\n",
        "df2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "collapsed": true,
        "id": "CzSACmMeIiR_",
        "outputId": "dd7a995a-46ec-4fa4-f834-cf1926c3e582"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['workclass', 'education', 'marital status', 'occupation',\n",
            "       'relationship', 'race', 'sex', 'native_country', 'income'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  fnlwgt  education_num  capital_gain  capital_loss  hrs_per_week  \\\n",
              "0   25  226802              7             0             0            40   \n",
              "1   38   89814              9             0             0            50   \n",
              "2   28  336951             12             0             0            40   \n",
              "3   44  160323             10          7688             0            40   \n",
              "4   18  103497             10             0             0            30   \n",
              "\n",
              "   workclass_ Local-gov  workclass_ Never-worked  workclass_ Private  \\\n",
              "0                 False                    False                True   \n",
              "1                 False                    False                True   \n",
              "2                  True                    False               False   \n",
              "3                 False                    False                True   \n",
              "4                 False                    False               False   \n",
              "\n",
              "   workclass_ Self-emp-inc  ...  native_country_ Puerto-Rico  \\\n",
              "0                    False  ...                        False   \n",
              "1                    False  ...                        False   \n",
              "2                    False  ...                        False   \n",
              "3                    False  ...                        False   \n",
              "4                    False  ...                        False   \n",
              "\n",
              "   native_country_ Scotland  native_country_ South  native_country_ Taiwan  \\\n",
              "0                     False                  False                   False   \n",
              "1                     False                  False                   False   \n",
              "2                     False                  False                   False   \n",
              "3                     False                  False                   False   \n",
              "4                     False                  False                   False   \n",
              "\n",
              "   native_country_ Thailand  native_country_ Trinadad&Tobago  \\\n",
              "0                     False                            False   \n",
              "1                     False                            False   \n",
              "2                     False                            False   \n",
              "3                     False                            False   \n",
              "4                     False                            False   \n",
              "\n",
              "   native_country_ United-States  native_country_ Vietnam  \\\n",
              "0                           True                    False   \n",
              "1                           True                    False   \n",
              "2                           True                    False   \n",
              "3                           True                    False   \n",
              "4                           True                    False   \n",
              "\n",
              "   native_country_ Yugoslavia  income_ >50K.  \n",
              "0                       False          False  \n",
              "1                       False          False  \n",
              "2                       False           True  \n",
              "3                       False           True  \n",
              "4                       False          False  \n",
              "\n",
              "[5 rows x 97 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28004f95-2c39-4535-a5c7-9e3d5d77bc57\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education_num</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hrs_per_week</th>\n",
              "      <th>workclass_ Local-gov</th>\n",
              "      <th>workclass_ Never-worked</th>\n",
              "      <th>workclass_ Private</th>\n",
              "      <th>workclass_ Self-emp-inc</th>\n",
              "      <th>...</th>\n",
              "      <th>native_country_ Puerto-Rico</th>\n",
              "      <th>native_country_ Scotland</th>\n",
              "      <th>native_country_ South</th>\n",
              "      <th>native_country_ Taiwan</th>\n",
              "      <th>native_country_ Thailand</th>\n",
              "      <th>native_country_ Trinadad&amp;Tobago</th>\n",
              "      <th>native_country_ United-States</th>\n",
              "      <th>native_country_ Vietnam</th>\n",
              "      <th>native_country_ Yugoslavia</th>\n",
              "      <th>income_ &gt;50K.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>226802</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38</td>\n",
              "      <td>89814</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>336951</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>160323</td>\n",
              "      <td>10</td>\n",
              "      <td>7688</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>103497</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 97 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28004f95-2c39-4535-a5c7-9e3d5d77bc57')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28004f95-2c39-4535-a5c7-9e3d5d77bc57 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28004f95-2c39-4535-a5c7-9e3d5d77bc57');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test=df2.drop(columns=[\"income_ >50K.\"])\n",
        "y_test=df2[\"income_ >50K.\"]\n",
        "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_foS4pnZYIO",
        "outputId": "2fcfff7e-1f42-4bc3-bd9b-c4dc2a9b8cea"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32561, 97)\n",
            "(16281, 97)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_input = X_train.shape[1]\n",
        "n_hidden1 = 64\n",
        "n_hidden2 = 32\n",
        "n_output = 1\n",
        "np.random.seed(42)\n",
        "\n",
        "w1 = np.random.randn(n_hidden1, n_input) * np.sqrt(2 / n_input)\n",
        "b1 = np.zeros((n_hidden1, 1))\n",
        "\n",
        "w2 = np.random.randn(n_hidden2, n_hidden1) * np.sqrt(2 / n_hidden1)\n",
        "b2 = np.zeros((n_hidden2, 1))\n",
        "w3 = np.random.randn(n_output, n_hidden2) * np.sqrt(2 / n_hidden2)\n",
        "b3 = np.zeros((n_output, 1))"
      ],
      "metadata": {
        "id": "d_oZzhPADmOY"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solution(X, y, w1, b1, w2, b2, w3, b3):\n",
        "    epochs = 100000\n",
        "    lr = 0.01\n",
        "    eps = 1e-8\n",
        "\n",
        "    X = X.values.T\n",
        "    m = X.shape[1]\n",
        "    y = y.values.reshape(1, m)\n",
        "\n",
        "    for i in range(epochs):\n",
        "\n",
        "\n",
        "        idx = np.random.randint(0, m)\n",
        "        X_i = X[:, idx:idx+1]\n",
        "        y_i = y[:, idx:idx+1]\n",
        "\n",
        "\n",
        "        z1 = np.dot(w1, X_i) + b1\n",
        "        a1 = np.maximum(0, z1)\n",
        "\n",
        "        z2 = np.dot(w2, a1) + b2\n",
        "        a2 = np.maximum(0, z2)\n",
        "\n",
        "        z3 = np.dot(w3, a2) + b3\n",
        "        y_hat = 1 / (1 + np.exp(-np.clip(z3, -500, 500)))\n",
        "\n",
        "\n",
        "        dz3 = y_hat - y_i\n",
        "        dw3 = np.dot(dz3, a2.T)\n",
        "        db3 = dz3\n",
        "\n",
        "        da2 = np.dot(w3.T, dz3)\n",
        "        dz2 = da2.copy()\n",
        "        dz2[z2 <= 0] = 0\n",
        "        dw2 = np.dot(dz2, a1.T)\n",
        "        db2 = dz2\n",
        "\n",
        "        da1 = np.dot(w2.T, dz2)\n",
        "        dz1 = da1.copy()\n",
        "        dz1[z1 <= 0] = 0\n",
        "        dw1 = np.dot(dz1, X_i.T)\n",
        "        db1 = dz1\n",
        "\n",
        "\n",
        "        w3 -= lr * dw3\n",
        "        b3 -= lr * db3\n",
        "        w2 -= lr * dw2\n",
        "        b2 -= lr * db2\n",
        "        w1 -= lr * dw1\n",
        "        b1 -= lr * db1\n",
        "\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            Z1_all = np.dot(w1, X) + b1\n",
        "            A1_all = np.maximum(0, Z1_all)\n",
        "\n",
        "            Z2_all = np.dot(w2, A1_all) + b2\n",
        "            A2_all = np.maximum(0, Z2_all)\n",
        "\n",
        "            Z3_all = np.dot(w3, A2_all) + b3\n",
        "            Y_hat_all = 1 / (1 + np.exp(-np.clip(Z3_all, -500, 500)))\n",
        "\n",
        "\n",
        "            loss = -np.mean(y * np.log(Y_hat_all + eps) + (1 - y) * np.log(1 - Y_hat_all + eps))\n",
        "            print(f\"Iteration {i}, Dataset Loss: {loss:.4f}\")\n",
        "    return w1, b1, w2, b2, w3, b3\n"
      ],
      "metadata": {
        "id": "5zc_j090Ea_t"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1, b1, w2, b2, w3, b3 = solution(X_train,y_train,w1,b1,w2,b2,w3,b3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAiL34vhYvOg",
        "outputId": "674f0996-2173-4ac8-ab2a-578f5556d7e8",
        "collapsed": true
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Dataset Loss: 0.5523\n",
            "Iteration 100, Dataset Loss: 0.5527\n",
            "Iteration 200, Dataset Loss: 0.5520\n",
            "Iteration 300, Dataset Loss: 0.5520\n",
            "Iteration 400, Dataset Loss: 0.5522\n",
            "Iteration 500, Dataset Loss: 0.5521\n",
            "Iteration 600, Dataset Loss: 0.5529\n",
            "Iteration 700, Dataset Loss: 0.5530\n",
            "Iteration 800, Dataset Loss: 0.5522\n",
            "Iteration 900, Dataset Loss: 0.5520\n",
            "Iteration 1000, Dataset Loss: 0.5521\n",
            "Iteration 1100, Dataset Loss: 0.5522\n",
            "Iteration 1200, Dataset Loss: 0.5521\n",
            "Iteration 1300, Dataset Loss: 0.5522\n",
            "Iteration 1400, Dataset Loss: 0.5522\n",
            "Iteration 1500, Dataset Loss: 0.5521\n",
            "Iteration 1600, Dataset Loss: 0.5521\n",
            "Iteration 1700, Dataset Loss: 0.5520\n",
            "Iteration 1800, Dataset Loss: 0.5520\n",
            "Iteration 1900, Dataset Loss: 0.5524\n",
            "Iteration 2000, Dataset Loss: 0.5525\n",
            "Iteration 2100, Dataset Loss: 0.5521\n",
            "Iteration 2200, Dataset Loss: 0.5521\n",
            "Iteration 2300, Dataset Loss: 0.5524\n",
            "Iteration 2400, Dataset Loss: 0.5524\n",
            "Iteration 2500, Dataset Loss: 0.5522\n",
            "Iteration 2600, Dataset Loss: 0.5521\n",
            "Iteration 2700, Dataset Loss: 0.5521\n",
            "Iteration 2800, Dataset Loss: 0.5521\n",
            "Iteration 2900, Dataset Loss: 0.5520\n",
            "Iteration 3000, Dataset Loss: 0.5523\n",
            "Iteration 3100, Dataset Loss: 0.5520\n",
            "Iteration 3200, Dataset Loss: 0.5521\n",
            "Iteration 3300, Dataset Loss: 0.5520\n",
            "Iteration 3400, Dataset Loss: 0.5523\n",
            "Iteration 3500, Dataset Loss: 0.5520\n",
            "Iteration 3600, Dataset Loss: 0.5520\n",
            "Iteration 3700, Dataset Loss: 0.5521\n",
            "Iteration 3800, Dataset Loss: 0.5521\n",
            "Iteration 3900, Dataset Loss: 0.5523\n",
            "Iteration 4000, Dataset Loss: 0.5520\n",
            "Iteration 4100, Dataset Loss: 0.5521\n",
            "Iteration 4200, Dataset Loss: 0.5520\n",
            "Iteration 4300, Dataset Loss: 0.5520\n",
            "Iteration 4400, Dataset Loss: 0.5523\n",
            "Iteration 4500, Dataset Loss: 0.5527\n",
            "Iteration 4600, Dataset Loss: 0.5524\n",
            "Iteration 4700, Dataset Loss: 0.5521\n",
            "Iteration 4800, Dataset Loss: 0.5520\n",
            "Iteration 4900, Dataset Loss: 0.5520\n",
            "Iteration 5000, Dataset Loss: 0.5525\n",
            "Iteration 5100, Dataset Loss: 0.5531\n",
            "Iteration 5200, Dataset Loss: 0.5529\n",
            "Iteration 5300, Dataset Loss: 0.5526\n",
            "Iteration 5400, Dataset Loss: 0.5521\n",
            "Iteration 5500, Dataset Loss: 0.5525\n",
            "Iteration 5600, Dataset Loss: 0.5522\n",
            "Iteration 5700, Dataset Loss: 0.5525\n",
            "Iteration 5800, Dataset Loss: 0.5522\n",
            "Iteration 5900, Dataset Loss: 0.5524\n",
            "Iteration 6000, Dataset Loss: 0.5520\n",
            "Iteration 6100, Dataset Loss: 0.5523\n",
            "Iteration 6200, Dataset Loss: 0.5522\n",
            "Iteration 6300, Dataset Loss: 0.5524\n",
            "Iteration 6400, Dataset Loss: 0.5523\n",
            "Iteration 6500, Dataset Loss: 0.5520\n",
            "Iteration 6600, Dataset Loss: 0.5523\n",
            "Iteration 6700, Dataset Loss: 0.5524\n",
            "Iteration 6800, Dataset Loss: 0.5530\n",
            "Iteration 6900, Dataset Loss: 0.5520\n",
            "Iteration 7000, Dataset Loss: 0.5520\n",
            "Iteration 7100, Dataset Loss: 0.5522\n",
            "Iteration 7200, Dataset Loss: 0.5522\n",
            "Iteration 7300, Dataset Loss: 0.5521\n",
            "Iteration 7400, Dataset Loss: 0.5520\n",
            "Iteration 7500, Dataset Loss: 0.5521\n",
            "Iteration 7600, Dataset Loss: 0.5523\n",
            "Iteration 7700, Dataset Loss: 0.5522\n",
            "Iteration 7800, Dataset Loss: 0.5523\n",
            "Iteration 7900, Dataset Loss: 0.5533\n",
            "Iteration 8000, Dataset Loss: 0.5527\n",
            "Iteration 8100, Dataset Loss: 0.5534\n",
            "Iteration 8200, Dataset Loss: 0.5540\n",
            "Iteration 8300, Dataset Loss: 0.5538\n",
            "Iteration 8400, Dataset Loss: 0.5536\n",
            "Iteration 8500, Dataset Loss: 0.5530\n",
            "Iteration 8600, Dataset Loss: 0.5530\n",
            "Iteration 8700, Dataset Loss: 0.5520\n",
            "Iteration 8800, Dataset Loss: 0.5523\n",
            "Iteration 8900, Dataset Loss: 0.5525\n",
            "Iteration 9000, Dataset Loss: 0.5521\n",
            "Iteration 9100, Dataset Loss: 0.5520\n",
            "Iteration 9200, Dataset Loss: 0.5521\n",
            "Iteration 9300, Dataset Loss: 0.5521\n",
            "Iteration 9400, Dataset Loss: 0.5520\n",
            "Iteration 9500, Dataset Loss: 0.5524\n",
            "Iteration 9600, Dataset Loss: 0.5523\n",
            "Iteration 9700, Dataset Loss: 0.5527\n",
            "Iteration 9800, Dataset Loss: 0.5539\n",
            "Iteration 9900, Dataset Loss: 0.5558\n",
            "Iteration 10000, Dataset Loss: 0.5550\n",
            "Iteration 10100, Dataset Loss: 0.5535\n",
            "Iteration 10200, Dataset Loss: 0.5529\n",
            "Iteration 10300, Dataset Loss: 0.5520\n",
            "Iteration 10400, Dataset Loss: 0.5520\n",
            "Iteration 10500, Dataset Loss: 0.5520\n",
            "Iteration 10600, Dataset Loss: 0.5523\n",
            "Iteration 10700, Dataset Loss: 0.5520\n",
            "Iteration 10800, Dataset Loss: 0.5528\n",
            "Iteration 10900, Dataset Loss: 0.5521\n",
            "Iteration 11000, Dataset Loss: 0.5524\n",
            "Iteration 11100, Dataset Loss: 0.5521\n",
            "Iteration 11200, Dataset Loss: 0.5521\n",
            "Iteration 11300, Dataset Loss: 0.5520\n",
            "Iteration 11400, Dataset Loss: 0.5520\n",
            "Iteration 11500, Dataset Loss: 0.5520\n",
            "Iteration 11600, Dataset Loss: 0.5523\n",
            "Iteration 11700, Dataset Loss: 0.5526\n",
            "Iteration 11800, Dataset Loss: 0.5526\n",
            "Iteration 11900, Dataset Loss: 0.5522\n",
            "Iteration 12000, Dataset Loss: 0.5520\n",
            "Iteration 12100, Dataset Loss: 0.5520\n",
            "Iteration 12200, Dataset Loss: 0.5521\n",
            "Iteration 12300, Dataset Loss: 0.5520\n",
            "Iteration 12400, Dataset Loss: 0.5521\n",
            "Iteration 12500, Dataset Loss: 0.5523\n",
            "Iteration 12600, Dataset Loss: 0.5520\n",
            "Iteration 12700, Dataset Loss: 0.5520\n",
            "Iteration 12800, Dataset Loss: 0.5520\n",
            "Iteration 12900, Dataset Loss: 0.5522\n",
            "Iteration 13000, Dataset Loss: 0.5528\n",
            "Iteration 13100, Dataset Loss: 0.5527\n",
            "Iteration 13200, Dataset Loss: 0.5525\n",
            "Iteration 13300, Dataset Loss: 0.5523\n",
            "Iteration 13400, Dataset Loss: 0.5525\n",
            "Iteration 13500, Dataset Loss: 0.5527\n",
            "Iteration 13600, Dataset Loss: 0.5526\n",
            "Iteration 13700, Dataset Loss: 0.5528\n",
            "Iteration 13800, Dataset Loss: 0.5527\n",
            "Iteration 13900, Dataset Loss: 0.5520\n",
            "Iteration 14000, Dataset Loss: 0.5520\n",
            "Iteration 14100, Dataset Loss: 0.5521\n",
            "Iteration 14200, Dataset Loss: 0.5521\n",
            "Iteration 14300, Dataset Loss: 0.5520\n",
            "Iteration 14400, Dataset Loss: 0.5520\n",
            "Iteration 14500, Dataset Loss: 0.5522\n",
            "Iteration 14600, Dataset Loss: 0.5520\n",
            "Iteration 14700, Dataset Loss: 0.5523\n",
            "Iteration 14800, Dataset Loss: 0.5521\n",
            "Iteration 14900, Dataset Loss: 0.5523\n",
            "Iteration 15000, Dataset Loss: 0.5525\n",
            "Iteration 15100, Dataset Loss: 0.5526\n",
            "Iteration 15200, Dataset Loss: 0.5525\n",
            "Iteration 15300, Dataset Loss: 0.5525\n",
            "Iteration 15400, Dataset Loss: 0.5532\n",
            "Iteration 15500, Dataset Loss: 0.5530\n",
            "Iteration 15600, Dataset Loss: 0.5527\n",
            "Iteration 15700, Dataset Loss: 0.5523\n",
            "Iteration 15800, Dataset Loss: 0.5521\n",
            "Iteration 15900, Dataset Loss: 0.5540\n",
            "Iteration 16000, Dataset Loss: 0.5532\n",
            "Iteration 16100, Dataset Loss: 0.5533\n",
            "Iteration 16200, Dataset Loss: 0.5528\n",
            "Iteration 16300, Dataset Loss: 0.5522\n",
            "Iteration 16400, Dataset Loss: 0.5520\n",
            "Iteration 16500, Dataset Loss: 0.5522\n",
            "Iteration 16600, Dataset Loss: 0.5520\n",
            "Iteration 16700, Dataset Loss: 0.5523\n",
            "Iteration 16800, Dataset Loss: 0.5527\n",
            "Iteration 16900, Dataset Loss: 0.5527\n",
            "Iteration 17000, Dataset Loss: 0.5522\n",
            "Iteration 17100, Dataset Loss: 0.5520\n",
            "Iteration 17200, Dataset Loss: 0.5523\n",
            "Iteration 17300, Dataset Loss: 0.5524\n",
            "Iteration 17400, Dataset Loss: 0.5525\n",
            "Iteration 17500, Dataset Loss: 0.5524\n",
            "Iteration 17600, Dataset Loss: 0.5522\n",
            "Iteration 17700, Dataset Loss: 0.5520\n",
            "Iteration 17800, Dataset Loss: 0.5520\n",
            "Iteration 17900, Dataset Loss: 0.5520\n",
            "Iteration 18000, Dataset Loss: 0.5520\n",
            "Iteration 18100, Dataset Loss: 0.5523\n",
            "Iteration 18200, Dataset Loss: 0.5522\n",
            "Iteration 18300, Dataset Loss: 0.5525\n",
            "Iteration 18400, Dataset Loss: 0.5526\n",
            "Iteration 18500, Dataset Loss: 0.5537\n",
            "Iteration 18600, Dataset Loss: 0.5544\n",
            "Iteration 18700, Dataset Loss: 0.5538\n",
            "Iteration 18800, Dataset Loss: 0.5528\n",
            "Iteration 18900, Dataset Loss: 0.5520\n",
            "Iteration 19000, Dataset Loss: 0.5521\n",
            "Iteration 19100, Dataset Loss: 0.5520\n",
            "Iteration 19200, Dataset Loss: 0.5521\n",
            "Iteration 19300, Dataset Loss: 0.5520\n",
            "Iteration 19400, Dataset Loss: 0.5525\n",
            "Iteration 19500, Dataset Loss: 0.5527\n",
            "Iteration 19600, Dataset Loss: 0.5534\n",
            "Iteration 19700, Dataset Loss: 0.5531\n",
            "Iteration 19800, Dataset Loss: 0.5532\n",
            "Iteration 19900, Dataset Loss: 0.5522\n",
            "Iteration 20000, Dataset Loss: 0.5533\n",
            "Iteration 20100, Dataset Loss: 0.5523\n",
            "Iteration 20200, Dataset Loss: 0.5521\n",
            "Iteration 20300, Dataset Loss: 0.5522\n",
            "Iteration 20400, Dataset Loss: 0.5521\n",
            "Iteration 20500, Dataset Loss: 0.5520\n",
            "Iteration 20600, Dataset Loss: 0.5521\n",
            "Iteration 20700, Dataset Loss: 0.5521\n",
            "Iteration 20800, Dataset Loss: 0.5521\n",
            "Iteration 20900, Dataset Loss: 0.5522\n",
            "Iteration 21000, Dataset Loss: 0.5527\n",
            "Iteration 21100, Dataset Loss: 0.5522\n",
            "Iteration 21200, Dataset Loss: 0.5521\n",
            "Iteration 21300, Dataset Loss: 0.5521\n",
            "Iteration 21400, Dataset Loss: 0.5524\n",
            "Iteration 21500, Dataset Loss: 0.5524\n",
            "Iteration 21600, Dataset Loss: 0.5524\n",
            "Iteration 21700, Dataset Loss: 0.5522\n",
            "Iteration 21800, Dataset Loss: 0.5521\n",
            "Iteration 21900, Dataset Loss: 0.5520\n",
            "Iteration 22000, Dataset Loss: 0.5521\n",
            "Iteration 22100, Dataset Loss: 0.5520\n",
            "Iteration 22200, Dataset Loss: 0.5531\n",
            "Iteration 22300, Dataset Loss: 0.5528\n",
            "Iteration 22400, Dataset Loss: 0.5535\n",
            "Iteration 22500, Dataset Loss: 0.5530\n",
            "Iteration 22600, Dataset Loss: 0.5523\n",
            "Iteration 22700, Dataset Loss: 0.5521\n",
            "Iteration 22800, Dataset Loss: 0.5523\n",
            "Iteration 22900, Dataset Loss: 0.5524\n",
            "Iteration 23000, Dataset Loss: 0.5528\n",
            "Iteration 23100, Dataset Loss: 0.5523\n",
            "Iteration 23200, Dataset Loss: 0.5524\n",
            "Iteration 23300, Dataset Loss: 0.5530\n",
            "Iteration 23400, Dataset Loss: 0.5522\n",
            "Iteration 23500, Dataset Loss: 0.5526\n",
            "Iteration 23600, Dataset Loss: 0.5521\n",
            "Iteration 23700, Dataset Loss: 0.5522\n",
            "Iteration 23800, Dataset Loss: 0.5522\n",
            "Iteration 23900, Dataset Loss: 0.5525\n",
            "Iteration 24000, Dataset Loss: 0.5525\n",
            "Iteration 24100, Dataset Loss: 0.5522\n",
            "Iteration 24200, Dataset Loss: 0.5521\n",
            "Iteration 24300, Dataset Loss: 0.5534\n",
            "Iteration 24400, Dataset Loss: 0.5526\n",
            "Iteration 24500, Dataset Loss: 0.5525\n",
            "Iteration 24600, Dataset Loss: 0.5523\n",
            "Iteration 24700, Dataset Loss: 0.5520\n",
            "Iteration 24800, Dataset Loss: 0.5528\n",
            "Iteration 24900, Dataset Loss: 0.5520\n",
            "Iteration 25000, Dataset Loss: 0.5523\n",
            "Iteration 25100, Dataset Loss: 0.5520\n",
            "Iteration 25200, Dataset Loss: 0.5521\n",
            "Iteration 25300, Dataset Loss: 0.5521\n",
            "Iteration 25400, Dataset Loss: 0.5520\n",
            "Iteration 25500, Dataset Loss: 0.5520\n",
            "Iteration 25600, Dataset Loss: 0.5522\n",
            "Iteration 25700, Dataset Loss: 0.5520\n",
            "Iteration 25800, Dataset Loss: 0.5522\n",
            "Iteration 25900, Dataset Loss: 0.5522\n",
            "Iteration 26000, Dataset Loss: 0.5525\n",
            "Iteration 26100, Dataset Loss: 0.5522\n",
            "Iteration 26200, Dataset Loss: 0.5523\n",
            "Iteration 26300, Dataset Loss: 0.5541\n",
            "Iteration 26400, Dataset Loss: 0.5553\n",
            "Iteration 26500, Dataset Loss: 0.5539\n",
            "Iteration 26600, Dataset Loss: 0.5532\n",
            "Iteration 26700, Dataset Loss: 0.5524\n",
            "Iteration 26800, Dataset Loss: 0.5523\n",
            "Iteration 26900, Dataset Loss: 0.5522\n",
            "Iteration 27000, Dataset Loss: 0.5520\n",
            "Iteration 27100, Dataset Loss: 0.5524\n",
            "Iteration 27200, Dataset Loss: 0.5520\n",
            "Iteration 27300, Dataset Loss: 0.5521\n",
            "Iteration 27400, Dataset Loss: 0.5521\n",
            "Iteration 27500, Dataset Loss: 0.5520\n",
            "Iteration 27600, Dataset Loss: 0.5521\n",
            "Iteration 27700, Dataset Loss: 0.5520\n",
            "Iteration 27800, Dataset Loss: 0.5523\n",
            "Iteration 27900, Dataset Loss: 0.5521\n",
            "Iteration 28000, Dataset Loss: 0.5520\n",
            "Iteration 28100, Dataset Loss: 0.5523\n",
            "Iteration 28200, Dataset Loss: 0.5520\n",
            "Iteration 28300, Dataset Loss: 0.5522\n",
            "Iteration 28400, Dataset Loss: 0.5525\n",
            "Iteration 28500, Dataset Loss: 0.5531\n",
            "Iteration 28600, Dataset Loss: 0.5528\n",
            "Iteration 28700, Dataset Loss: 0.5525\n",
            "Iteration 28800, Dataset Loss: 0.5522\n",
            "Iteration 28900, Dataset Loss: 0.5523\n",
            "Iteration 29000, Dataset Loss: 0.5520\n",
            "Iteration 29100, Dataset Loss: 0.5523\n",
            "Iteration 29200, Dataset Loss: 0.5521\n",
            "Iteration 29300, Dataset Loss: 0.5523\n",
            "Iteration 29400, Dataset Loss: 0.5522\n",
            "Iteration 29500, Dataset Loss: 0.5521\n",
            "Iteration 29600, Dataset Loss: 0.5520\n",
            "Iteration 29700, Dataset Loss: 0.5521\n",
            "Iteration 29800, Dataset Loss: 0.5520\n",
            "Iteration 29900, Dataset Loss: 0.5539\n",
            "Iteration 30000, Dataset Loss: 0.5532\n",
            "Iteration 30100, Dataset Loss: 0.5525\n",
            "Iteration 30200, Dataset Loss: 0.5535\n",
            "Iteration 30300, Dataset Loss: 0.5529\n",
            "Iteration 30400, Dataset Loss: 0.5527\n",
            "Iteration 30500, Dataset Loss: 0.5521\n",
            "Iteration 30600, Dataset Loss: 0.5524\n",
            "Iteration 30700, Dataset Loss: 0.5528\n",
            "Iteration 30800, Dataset Loss: 0.5523\n",
            "Iteration 30900, Dataset Loss: 0.5520\n",
            "Iteration 31000, Dataset Loss: 0.5521\n",
            "Iteration 31100, Dataset Loss: 0.5520\n",
            "Iteration 31200, Dataset Loss: 0.5520\n",
            "Iteration 31300, Dataset Loss: 0.5525\n",
            "Iteration 31400, Dataset Loss: 0.5521\n",
            "Iteration 31500, Dataset Loss: 0.5522\n",
            "Iteration 31600, Dataset Loss: 0.5524\n",
            "Iteration 31700, Dataset Loss: 0.5525\n",
            "Iteration 31800, Dataset Loss: 0.5526\n",
            "Iteration 31900, Dataset Loss: 0.5528\n",
            "Iteration 32000, Dataset Loss: 0.5536\n",
            "Iteration 32100, Dataset Loss: 0.5534\n",
            "Iteration 32200, Dataset Loss: 0.5530\n",
            "Iteration 32300, Dataset Loss: 0.5532\n",
            "Iteration 32400, Dataset Loss: 0.5532\n",
            "Iteration 32500, Dataset Loss: 0.5540\n",
            "Iteration 32600, Dataset Loss: 0.5542\n",
            "Iteration 32700, Dataset Loss: 0.5532\n",
            "Iteration 32800, Dataset Loss: 0.5521\n",
            "Iteration 32900, Dataset Loss: 0.5521\n",
            "Iteration 33000, Dataset Loss: 0.5521\n",
            "Iteration 33100, Dataset Loss: 0.5521\n",
            "Iteration 33200, Dataset Loss: 0.5521\n",
            "Iteration 33300, Dataset Loss: 0.5520\n",
            "Iteration 33400, Dataset Loss: 0.5522\n",
            "Iteration 33500, Dataset Loss: 0.5521\n",
            "Iteration 33600, Dataset Loss: 0.5523\n",
            "Iteration 33700, Dataset Loss: 0.5532\n",
            "Iteration 33800, Dataset Loss: 0.5524\n",
            "Iteration 33900, Dataset Loss: 0.5520\n",
            "Iteration 34000, Dataset Loss: 0.5522\n",
            "Iteration 34100, Dataset Loss: 0.5521\n",
            "Iteration 34200, Dataset Loss: 0.5521\n",
            "Iteration 34300, Dataset Loss: 0.5521\n",
            "Iteration 34400, Dataset Loss: 0.5521\n",
            "Iteration 34500, Dataset Loss: 0.5521\n",
            "Iteration 34600, Dataset Loss: 0.5521\n",
            "Iteration 34700, Dataset Loss: 0.5522\n",
            "Iteration 34800, Dataset Loss: 0.5521\n",
            "Iteration 34900, Dataset Loss: 0.5521\n",
            "Iteration 35000, Dataset Loss: 0.5521\n",
            "Iteration 35100, Dataset Loss: 0.5521\n",
            "Iteration 35200, Dataset Loss: 0.5520\n",
            "Iteration 35300, Dataset Loss: 0.5521\n",
            "Iteration 35400, Dataset Loss: 0.5531\n",
            "Iteration 35500, Dataset Loss: 0.5528\n",
            "Iteration 35600, Dataset Loss: 0.5540\n",
            "Iteration 35700, Dataset Loss: 0.5522\n",
            "Iteration 35800, Dataset Loss: 0.5520\n",
            "Iteration 35900, Dataset Loss: 0.5520\n",
            "Iteration 36000, Dataset Loss: 0.5520\n",
            "Iteration 36100, Dataset Loss: 0.5521\n",
            "Iteration 36200, Dataset Loss: 0.5520\n",
            "Iteration 36300, Dataset Loss: 0.5521\n",
            "Iteration 36400, Dataset Loss: 0.5521\n",
            "Iteration 36500, Dataset Loss: 0.5526\n",
            "Iteration 36600, Dataset Loss: 0.5530\n",
            "Iteration 36700, Dataset Loss: 0.5527\n",
            "Iteration 36800, Dataset Loss: 0.5527\n",
            "Iteration 36900, Dataset Loss: 0.5523\n",
            "Iteration 37000, Dataset Loss: 0.5520\n",
            "Iteration 37100, Dataset Loss: 0.5520\n",
            "Iteration 37200, Dataset Loss: 0.5520\n",
            "Iteration 37300, Dataset Loss: 0.5520\n",
            "Iteration 37400, Dataset Loss: 0.5525\n",
            "Iteration 37500, Dataset Loss: 0.5524\n",
            "Iteration 37600, Dataset Loss: 0.5545\n",
            "Iteration 37700, Dataset Loss: 0.5540\n",
            "Iteration 37800, Dataset Loss: 0.5532\n",
            "Iteration 37900, Dataset Loss: 0.5536\n",
            "Iteration 38000, Dataset Loss: 0.5527\n",
            "Iteration 38100, Dataset Loss: 0.5523\n",
            "Iteration 38200, Dataset Loss: 0.5522\n",
            "Iteration 38300, Dataset Loss: 0.5520\n",
            "Iteration 38400, Dataset Loss: 0.5520\n",
            "Iteration 38500, Dataset Loss: 0.5521\n",
            "Iteration 38600, Dataset Loss: 0.5523\n",
            "Iteration 38700, Dataset Loss: 0.5533\n",
            "Iteration 38800, Dataset Loss: 0.5526\n",
            "Iteration 38900, Dataset Loss: 0.5520\n",
            "Iteration 39000, Dataset Loss: 0.5523\n",
            "Iteration 39100, Dataset Loss: 0.5528\n",
            "Iteration 39200, Dataset Loss: 0.5526\n",
            "Iteration 39300, Dataset Loss: 0.5524\n",
            "Iteration 39400, Dataset Loss: 0.5523\n",
            "Iteration 39500, Dataset Loss: 0.5520\n",
            "Iteration 39600, Dataset Loss: 0.5521\n",
            "Iteration 39700, Dataset Loss: 0.5521\n",
            "Iteration 39800, Dataset Loss: 0.5520\n",
            "Iteration 39900, Dataset Loss: 0.5521\n",
            "Iteration 40000, Dataset Loss: 0.5521\n",
            "Iteration 40100, Dataset Loss: 0.5528\n",
            "Iteration 40200, Dataset Loss: 0.5523\n",
            "Iteration 40300, Dataset Loss: 0.5522\n",
            "Iteration 40400, Dataset Loss: 0.5521\n",
            "Iteration 40500, Dataset Loss: 0.5520\n",
            "Iteration 40600, Dataset Loss: 0.5521\n",
            "Iteration 40700, Dataset Loss: 0.5520\n",
            "Iteration 40800, Dataset Loss: 0.5521\n",
            "Iteration 40900, Dataset Loss: 0.5521\n",
            "Iteration 41000, Dataset Loss: 0.5521\n",
            "Iteration 41100, Dataset Loss: 0.5520\n",
            "Iteration 41200, Dataset Loss: 0.5522\n",
            "Iteration 41300, Dataset Loss: 0.5521\n",
            "Iteration 41400, Dataset Loss: 0.5522\n",
            "Iteration 41500, Dataset Loss: 0.5523\n",
            "Iteration 41600, Dataset Loss: 0.5520\n",
            "Iteration 41700, Dataset Loss: 0.5522\n",
            "Iteration 41800, Dataset Loss: 0.5522\n",
            "Iteration 41900, Dataset Loss: 0.5520\n",
            "Iteration 42000, Dataset Loss: 0.5521\n",
            "Iteration 42100, Dataset Loss: 0.5526\n",
            "Iteration 42200, Dataset Loss: 0.5525\n",
            "Iteration 42300, Dataset Loss: 0.5532\n",
            "Iteration 42400, Dataset Loss: 0.5523\n",
            "Iteration 42500, Dataset Loss: 0.5524\n",
            "Iteration 42600, Dataset Loss: 0.5533\n",
            "Iteration 42700, Dataset Loss: 0.5525\n",
            "Iteration 42800, Dataset Loss: 0.5533\n",
            "Iteration 42900, Dataset Loss: 0.5531\n",
            "Iteration 43000, Dataset Loss: 0.5523\n",
            "Iteration 43100, Dataset Loss: 0.5520\n",
            "Iteration 43200, Dataset Loss: 0.5523\n",
            "Iteration 43300, Dataset Loss: 0.5521\n",
            "Iteration 43400, Dataset Loss: 0.5521\n",
            "Iteration 43500, Dataset Loss: 0.5520\n",
            "Iteration 43600, Dataset Loss: 0.5522\n",
            "Iteration 43700, Dataset Loss: 0.5522\n",
            "Iteration 43800, Dataset Loss: 0.5520\n",
            "Iteration 43900, Dataset Loss: 0.5524\n",
            "Iteration 44000, Dataset Loss: 0.5520\n",
            "Iteration 44100, Dataset Loss: 0.5523\n",
            "Iteration 44200, Dataset Loss: 0.5522\n",
            "Iteration 44300, Dataset Loss: 0.5522\n",
            "Iteration 44400, Dataset Loss: 0.5521\n",
            "Iteration 44500, Dataset Loss: 0.5520\n",
            "Iteration 44600, Dataset Loss: 0.5520\n",
            "Iteration 44700, Dataset Loss: 0.5520\n",
            "Iteration 44800, Dataset Loss: 0.5520\n",
            "Iteration 44900, Dataset Loss: 0.5520\n",
            "Iteration 45000, Dataset Loss: 0.5521\n",
            "Iteration 45100, Dataset Loss: 0.5521\n",
            "Iteration 45200, Dataset Loss: 0.5520\n",
            "Iteration 45300, Dataset Loss: 0.5520\n",
            "Iteration 45400, Dataset Loss: 0.5520\n",
            "Iteration 45500, Dataset Loss: 0.5522\n",
            "Iteration 45600, Dataset Loss: 0.5526\n",
            "Iteration 45700, Dataset Loss: 0.5523\n",
            "Iteration 45800, Dataset Loss: 0.5523\n",
            "Iteration 45900, Dataset Loss: 0.5521\n",
            "Iteration 46000, Dataset Loss: 0.5520\n",
            "Iteration 46100, Dataset Loss: 0.5521\n",
            "Iteration 46200, Dataset Loss: 0.5523\n",
            "Iteration 46300, Dataset Loss: 0.5522\n",
            "Iteration 46400, Dataset Loss: 0.5524\n",
            "Iteration 46500, Dataset Loss: 0.5520\n",
            "Iteration 46600, Dataset Loss: 0.5524\n",
            "Iteration 46700, Dataset Loss: 0.5522\n",
            "Iteration 46800, Dataset Loss: 0.5523\n",
            "Iteration 46900, Dataset Loss: 0.5522\n",
            "Iteration 47000, Dataset Loss: 0.5532\n",
            "Iteration 47100, Dataset Loss: 0.5528\n",
            "Iteration 47200, Dataset Loss: 0.5523\n",
            "Iteration 47300, Dataset Loss: 0.5528\n",
            "Iteration 47400, Dataset Loss: 0.5529\n",
            "Iteration 47500, Dataset Loss: 0.5534\n",
            "Iteration 47600, Dataset Loss: 0.5523\n",
            "Iteration 47700, Dataset Loss: 0.5520\n",
            "Iteration 47800, Dataset Loss: 0.5521\n",
            "Iteration 47900, Dataset Loss: 0.5520\n",
            "Iteration 48000, Dataset Loss: 0.5522\n",
            "Iteration 48100, Dataset Loss: 0.5523\n",
            "Iteration 48200, Dataset Loss: 0.5521\n",
            "Iteration 48300, Dataset Loss: 0.5520\n",
            "Iteration 48400, Dataset Loss: 0.5523\n",
            "Iteration 48500, Dataset Loss: 0.5524\n",
            "Iteration 48600, Dataset Loss: 0.5520\n",
            "Iteration 48700, Dataset Loss: 0.5521\n",
            "Iteration 48800, Dataset Loss: 0.5520\n",
            "Iteration 48900, Dataset Loss: 0.5521\n",
            "Iteration 49000, Dataset Loss: 0.5522\n",
            "Iteration 49100, Dataset Loss: 0.5522\n",
            "Iteration 49200, Dataset Loss: 0.5523\n",
            "Iteration 49300, Dataset Loss: 0.5521\n",
            "Iteration 49400, Dataset Loss: 0.5521\n",
            "Iteration 49500, Dataset Loss: 0.5530\n",
            "Iteration 49600, Dataset Loss: 0.5532\n",
            "Iteration 49700, Dataset Loss: 0.5522\n",
            "Iteration 49800, Dataset Loss: 0.5523\n",
            "Iteration 49900, Dataset Loss: 0.5520\n",
            "Iteration 50000, Dataset Loss: 0.5521\n",
            "Iteration 50100, Dataset Loss: 0.5521\n",
            "Iteration 50200, Dataset Loss: 0.5521\n",
            "Iteration 50300, Dataset Loss: 0.5520\n",
            "Iteration 50400, Dataset Loss: 0.5520\n",
            "Iteration 50500, Dataset Loss: 0.5520\n",
            "Iteration 50600, Dataset Loss: 0.5528\n",
            "Iteration 50700, Dataset Loss: 0.5525\n",
            "Iteration 50800, Dataset Loss: 0.5522\n",
            "Iteration 50900, Dataset Loss: 0.5522\n",
            "Iteration 51000, Dataset Loss: 0.5520\n",
            "Iteration 51100, Dataset Loss: 0.5520\n",
            "Iteration 51200, Dataset Loss: 0.5525\n",
            "Iteration 51300, Dataset Loss: 0.5521\n",
            "Iteration 51400, Dataset Loss: 0.5520\n",
            "Iteration 51500, Dataset Loss: 0.5520\n",
            "Iteration 51600, Dataset Loss: 0.5521\n",
            "Iteration 51700, Dataset Loss: 0.5522\n",
            "Iteration 51800, Dataset Loss: 0.5520\n",
            "Iteration 51900, Dataset Loss: 0.5523\n",
            "Iteration 52000, Dataset Loss: 0.5522\n",
            "Iteration 52100, Dataset Loss: 0.5521\n",
            "Iteration 52200, Dataset Loss: 0.5524\n",
            "Iteration 52300, Dataset Loss: 0.5525\n",
            "Iteration 52400, Dataset Loss: 0.5521\n",
            "Iteration 52500, Dataset Loss: 0.5527\n",
            "Iteration 52600, Dataset Loss: 0.5528\n",
            "Iteration 52700, Dataset Loss: 0.5539\n",
            "Iteration 52800, Dataset Loss: 0.5527\n",
            "Iteration 52900, Dataset Loss: 0.5523\n",
            "Iteration 53000, Dataset Loss: 0.5522\n",
            "Iteration 53100, Dataset Loss: 0.5528\n",
            "Iteration 53200, Dataset Loss: 0.5532\n",
            "Iteration 53300, Dataset Loss: 0.5522\n",
            "Iteration 53400, Dataset Loss: 0.5524\n",
            "Iteration 53500, Dataset Loss: 0.5522\n",
            "Iteration 53600, Dataset Loss: 0.5532\n",
            "Iteration 53700, Dataset Loss: 0.5539\n",
            "Iteration 53800, Dataset Loss: 0.5525\n",
            "Iteration 53900, Dataset Loss: 0.5526\n",
            "Iteration 54000, Dataset Loss: 0.5522\n",
            "Iteration 54100, Dataset Loss: 0.5526\n",
            "Iteration 54200, Dataset Loss: 0.5527\n",
            "Iteration 54300, Dataset Loss: 0.5522\n",
            "Iteration 54400, Dataset Loss: 0.5531\n",
            "Iteration 54500, Dataset Loss: 0.5535\n",
            "Iteration 54600, Dataset Loss: 0.5532\n",
            "Iteration 54700, Dataset Loss: 0.5531\n",
            "Iteration 54800, Dataset Loss: 0.5521\n",
            "Iteration 54900, Dataset Loss: 0.5532\n",
            "Iteration 55000, Dataset Loss: 0.5558\n",
            "Iteration 55100, Dataset Loss: 0.5555\n",
            "Iteration 55200, Dataset Loss: 0.5528\n",
            "Iteration 55300, Dataset Loss: 0.5525\n",
            "Iteration 55400, Dataset Loss: 0.5527\n",
            "Iteration 55500, Dataset Loss: 0.5533\n",
            "Iteration 55600, Dataset Loss: 0.5532\n",
            "Iteration 55700, Dataset Loss: 0.5542\n",
            "Iteration 55800, Dataset Loss: 0.5535\n",
            "Iteration 55900, Dataset Loss: 0.5524\n",
            "Iteration 56000, Dataset Loss: 0.5523\n",
            "Iteration 56100, Dataset Loss: 0.5520\n",
            "Iteration 56200, Dataset Loss: 0.5520\n",
            "Iteration 56300, Dataset Loss: 0.5523\n",
            "Iteration 56400, Dataset Loss: 0.5523\n",
            "Iteration 56500, Dataset Loss: 0.5521\n",
            "Iteration 56600, Dataset Loss: 0.5521\n",
            "Iteration 56700, Dataset Loss: 0.5520\n",
            "Iteration 56800, Dataset Loss: 0.5522\n",
            "Iteration 56900, Dataset Loss: 0.5526\n",
            "Iteration 57000, Dataset Loss: 0.5529\n",
            "Iteration 57100, Dataset Loss: 0.5527\n",
            "Iteration 57200, Dataset Loss: 0.5520\n",
            "Iteration 57300, Dataset Loss: 0.5522\n",
            "Iteration 57400, Dataset Loss: 0.5521\n",
            "Iteration 57500, Dataset Loss: 0.5520\n",
            "Iteration 57600, Dataset Loss: 0.5520\n",
            "Iteration 57700, Dataset Loss: 0.5521\n",
            "Iteration 57800, Dataset Loss: 0.5520\n",
            "Iteration 57900, Dataset Loss: 0.5520\n",
            "Iteration 58000, Dataset Loss: 0.5520\n",
            "Iteration 58100, Dataset Loss: 0.5521\n",
            "Iteration 58200, Dataset Loss: 0.5522\n",
            "Iteration 58300, Dataset Loss: 0.5520\n",
            "Iteration 58400, Dataset Loss: 0.5520\n",
            "Iteration 58500, Dataset Loss: 0.5521\n",
            "Iteration 58600, Dataset Loss: 0.5520\n",
            "Iteration 58700, Dataset Loss: 0.5529\n",
            "Iteration 58800, Dataset Loss: 0.5535\n",
            "Iteration 58900, Dataset Loss: 0.5528\n",
            "Iteration 59000, Dataset Loss: 0.5547\n",
            "Iteration 59100, Dataset Loss: 0.5548\n",
            "Iteration 59200, Dataset Loss: 0.5545\n",
            "Iteration 59300, Dataset Loss: 0.5529\n",
            "Iteration 59400, Dataset Loss: 0.5522\n",
            "Iteration 59500, Dataset Loss: 0.5520\n",
            "Iteration 59600, Dataset Loss: 0.5524\n",
            "Iteration 59700, Dataset Loss: 0.5522\n",
            "Iteration 59800, Dataset Loss: 0.5531\n",
            "Iteration 59900, Dataset Loss: 0.5522\n",
            "Iteration 60000, Dataset Loss: 0.5524\n",
            "Iteration 60100, Dataset Loss: 0.5522\n",
            "Iteration 60200, Dataset Loss: 0.5521\n",
            "Iteration 60300, Dataset Loss: 0.5534\n",
            "Iteration 60400, Dataset Loss: 0.5530\n",
            "Iteration 60500, Dataset Loss: 0.5521\n",
            "Iteration 60600, Dataset Loss: 0.5539\n",
            "Iteration 60700, Dataset Loss: 0.5531\n",
            "Iteration 60800, Dataset Loss: 0.5537\n",
            "Iteration 60900, Dataset Loss: 0.5527\n",
            "Iteration 61000, Dataset Loss: 0.5529\n",
            "Iteration 61100, Dataset Loss: 0.5529\n",
            "Iteration 61200, Dataset Loss: 0.5531\n",
            "Iteration 61300, Dataset Loss: 0.5525\n",
            "Iteration 61400, Dataset Loss: 0.5528\n",
            "Iteration 61500, Dataset Loss: 0.5535\n",
            "Iteration 61600, Dataset Loss: 0.5548\n",
            "Iteration 61700, Dataset Loss: 0.5537\n",
            "Iteration 61800, Dataset Loss: 0.5539\n",
            "Iteration 61900, Dataset Loss: 0.5528\n",
            "Iteration 62000, Dataset Loss: 0.5523\n",
            "Iteration 62100, Dataset Loss: 0.5529\n",
            "Iteration 62200, Dataset Loss: 0.5528\n",
            "Iteration 62300, Dataset Loss: 0.5527\n",
            "Iteration 62400, Dataset Loss: 0.5522\n",
            "Iteration 62500, Dataset Loss: 0.5523\n",
            "Iteration 62600, Dataset Loss: 0.5521\n",
            "Iteration 62700, Dataset Loss: 0.5520\n",
            "Iteration 62800, Dataset Loss: 0.5520\n",
            "Iteration 62900, Dataset Loss: 0.5524\n",
            "Iteration 63000, Dataset Loss: 0.5520\n",
            "Iteration 63100, Dataset Loss: 0.5522\n",
            "Iteration 63200, Dataset Loss: 0.5521\n",
            "Iteration 63300, Dataset Loss: 0.5523\n",
            "Iteration 63400, Dataset Loss: 0.5525\n",
            "Iteration 63500, Dataset Loss: 0.5523\n",
            "Iteration 63600, Dataset Loss: 0.5531\n",
            "Iteration 63700, Dataset Loss: 0.5531\n",
            "Iteration 63800, Dataset Loss: 0.5528\n",
            "Iteration 63900, Dataset Loss: 0.5522\n",
            "Iteration 64000, Dataset Loss: 0.5521\n",
            "Iteration 64100, Dataset Loss: 0.5528\n",
            "Iteration 64200, Dataset Loss: 0.5529\n",
            "Iteration 64300, Dataset Loss: 0.5525\n",
            "Iteration 64400, Dataset Loss: 0.5521\n",
            "Iteration 64500, Dataset Loss: 0.5520\n",
            "Iteration 64600, Dataset Loss: 0.5521\n",
            "Iteration 64700, Dataset Loss: 0.5520\n",
            "Iteration 64800, Dataset Loss: 0.5520\n",
            "Iteration 64900, Dataset Loss: 0.5522\n",
            "Iteration 65000, Dataset Loss: 0.5520\n",
            "Iteration 65100, Dataset Loss: 0.5525\n",
            "Iteration 65200, Dataset Loss: 0.5521\n",
            "Iteration 65300, Dataset Loss: 0.5521\n",
            "Iteration 65400, Dataset Loss: 0.5520\n",
            "Iteration 65500, Dataset Loss: 0.5520\n",
            "Iteration 65600, Dataset Loss: 0.5524\n",
            "Iteration 65700, Dataset Loss: 0.5530\n",
            "Iteration 65800, Dataset Loss: 0.5521\n",
            "Iteration 65900, Dataset Loss: 0.5529\n",
            "Iteration 66000, Dataset Loss: 0.5523\n",
            "Iteration 66100, Dataset Loss: 0.5522\n",
            "Iteration 66200, Dataset Loss: 0.5520\n",
            "Iteration 66300, Dataset Loss: 0.5523\n",
            "Iteration 66400, Dataset Loss: 0.5520\n",
            "Iteration 66500, Dataset Loss: 0.5522\n",
            "Iteration 66600, Dataset Loss: 0.5520\n",
            "Iteration 66700, Dataset Loss: 0.5522\n",
            "Iteration 66800, Dataset Loss: 0.5522\n",
            "Iteration 66900, Dataset Loss: 0.5520\n",
            "Iteration 67000, Dataset Loss: 0.5520\n",
            "Iteration 67100, Dataset Loss: 0.5520\n",
            "Iteration 67200, Dataset Loss: 0.5520\n",
            "Iteration 67300, Dataset Loss: 0.5531\n",
            "Iteration 67400, Dataset Loss: 0.5540\n",
            "Iteration 67500, Dataset Loss: 0.5541\n",
            "Iteration 67600, Dataset Loss: 0.5532\n",
            "Iteration 67700, Dataset Loss: 0.5530\n",
            "Iteration 67800, Dataset Loss: 0.5521\n",
            "Iteration 67900, Dataset Loss: 0.5520\n",
            "Iteration 68000, Dataset Loss: 0.5525\n",
            "Iteration 68100, Dataset Loss: 0.5520\n",
            "Iteration 68200, Dataset Loss: 0.5521\n",
            "Iteration 68300, Dataset Loss: 0.5520\n",
            "Iteration 68400, Dataset Loss: 0.5521\n",
            "Iteration 68500, Dataset Loss: 0.5522\n",
            "Iteration 68600, Dataset Loss: 0.5520\n",
            "Iteration 68700, Dataset Loss: 0.5527\n",
            "Iteration 68800, Dataset Loss: 0.5528\n",
            "Iteration 68900, Dataset Loss: 0.5522\n",
            "Iteration 69000, Dataset Loss: 0.5524\n",
            "Iteration 69100, Dataset Loss: 0.5530\n",
            "Iteration 69200, Dataset Loss: 0.5530\n",
            "Iteration 69300, Dataset Loss: 0.5526\n",
            "Iteration 69400, Dataset Loss: 0.5534\n",
            "Iteration 69500, Dataset Loss: 0.5524\n",
            "Iteration 69600, Dataset Loss: 0.5521\n",
            "Iteration 69700, Dataset Loss: 0.5524\n",
            "Iteration 69800, Dataset Loss: 0.5520\n",
            "Iteration 69900, Dataset Loss: 0.5521\n",
            "Iteration 70000, Dataset Loss: 0.5525\n",
            "Iteration 70100, Dataset Loss: 0.5522\n",
            "Iteration 70200, Dataset Loss: 0.5535\n",
            "Iteration 70300, Dataset Loss: 0.5543\n",
            "Iteration 70400, Dataset Loss: 0.5534\n",
            "Iteration 70500, Dataset Loss: 0.5528\n",
            "Iteration 70600, Dataset Loss: 0.5524\n",
            "Iteration 70700, Dataset Loss: 0.5521\n",
            "Iteration 70800, Dataset Loss: 0.5520\n",
            "Iteration 70900, Dataset Loss: 0.5521\n",
            "Iteration 71000, Dataset Loss: 0.5522\n",
            "Iteration 71100, Dataset Loss: 0.5524\n",
            "Iteration 71200, Dataset Loss: 0.5520\n",
            "Iteration 71300, Dataset Loss: 0.5520\n",
            "Iteration 71400, Dataset Loss: 0.5521\n",
            "Iteration 71500, Dataset Loss: 0.5522\n",
            "Iteration 71600, Dataset Loss: 0.5522\n",
            "Iteration 71700, Dataset Loss: 0.5525\n",
            "Iteration 71800, Dataset Loss: 0.5520\n",
            "Iteration 71900, Dataset Loss: 0.5522\n",
            "Iteration 72000, Dataset Loss: 0.5520\n",
            "Iteration 72100, Dataset Loss: 0.5520\n",
            "Iteration 72200, Dataset Loss: 0.5520\n",
            "Iteration 72300, Dataset Loss: 0.5524\n",
            "Iteration 72400, Dataset Loss: 0.5526\n",
            "Iteration 72500, Dataset Loss: 0.5525\n",
            "Iteration 72600, Dataset Loss: 0.5522\n",
            "Iteration 72700, Dataset Loss: 0.5520\n",
            "Iteration 72800, Dataset Loss: 0.5524\n",
            "Iteration 72900, Dataset Loss: 0.5520\n",
            "Iteration 73000, Dataset Loss: 0.5521\n",
            "Iteration 73100, Dataset Loss: 0.5521\n",
            "Iteration 73200, Dataset Loss: 0.5520\n",
            "Iteration 73300, Dataset Loss: 0.5524\n",
            "Iteration 73400, Dataset Loss: 0.5525\n",
            "Iteration 73500, Dataset Loss: 0.5520\n",
            "Iteration 73600, Dataset Loss: 0.5521\n",
            "Iteration 73700, Dataset Loss: 0.5520\n",
            "Iteration 73800, Dataset Loss: 0.5522\n",
            "Iteration 73900, Dataset Loss: 0.5520\n",
            "Iteration 74000, Dataset Loss: 0.5520\n",
            "Iteration 74100, Dataset Loss: 0.5521\n",
            "Iteration 74200, Dataset Loss: 0.5521\n",
            "Iteration 74300, Dataset Loss: 0.5528\n",
            "Iteration 74400, Dataset Loss: 0.5521\n",
            "Iteration 74500, Dataset Loss: 0.5520\n",
            "Iteration 74600, Dataset Loss: 0.5521\n",
            "Iteration 74700, Dataset Loss: 0.5526\n",
            "Iteration 74800, Dataset Loss: 0.5525\n",
            "Iteration 74900, Dataset Loss: 0.5521\n",
            "Iteration 75000, Dataset Loss: 0.5520\n",
            "Iteration 75100, Dataset Loss: 0.5521\n",
            "Iteration 75200, Dataset Loss: 0.5520\n",
            "Iteration 75300, Dataset Loss: 0.5523\n",
            "Iteration 75400, Dataset Loss: 0.5535\n",
            "Iteration 75500, Dataset Loss: 0.5532\n",
            "Iteration 75600, Dataset Loss: 0.5523\n",
            "Iteration 75700, Dataset Loss: 0.5523\n",
            "Iteration 75800, Dataset Loss: 0.5522\n",
            "Iteration 75900, Dataset Loss: 0.5520\n",
            "Iteration 76000, Dataset Loss: 0.5521\n",
            "Iteration 76100, Dataset Loss: 0.5521\n",
            "Iteration 76200, Dataset Loss: 0.5524\n",
            "Iteration 76300, Dataset Loss: 0.5524\n",
            "Iteration 76400, Dataset Loss: 0.5520\n",
            "Iteration 76500, Dataset Loss: 0.5520\n",
            "Iteration 76600, Dataset Loss: 0.5524\n",
            "Iteration 76700, Dataset Loss: 0.5523\n",
            "Iteration 76800, Dataset Loss: 0.5526\n",
            "Iteration 76900, Dataset Loss: 0.5536\n",
            "Iteration 77000, Dataset Loss: 0.5537\n",
            "Iteration 77100, Dataset Loss: 0.5534\n",
            "Iteration 77200, Dataset Loss: 0.5537\n",
            "Iteration 77300, Dataset Loss: 0.5539\n",
            "Iteration 77400, Dataset Loss: 0.5526\n",
            "Iteration 77500, Dataset Loss: 0.5525\n",
            "Iteration 77600, Dataset Loss: 0.5535\n",
            "Iteration 77700, Dataset Loss: 0.5521\n",
            "Iteration 77800, Dataset Loss: 0.5534\n",
            "Iteration 77900, Dataset Loss: 0.5537\n",
            "Iteration 78000, Dataset Loss: 0.5529\n",
            "Iteration 78100, Dataset Loss: 0.5540\n",
            "Iteration 78200, Dataset Loss: 0.5553\n",
            "Iteration 78300, Dataset Loss: 0.5538\n",
            "Iteration 78400, Dataset Loss: 0.5524\n",
            "Iteration 78500, Dataset Loss: 0.5520\n",
            "Iteration 78600, Dataset Loss: 0.5520\n",
            "Iteration 78700, Dataset Loss: 0.5521\n",
            "Iteration 78800, Dataset Loss: 0.5523\n",
            "Iteration 78900, Dataset Loss: 0.5524\n",
            "Iteration 79000, Dataset Loss: 0.5523\n",
            "Iteration 79100, Dataset Loss: 0.5521\n",
            "Iteration 79200, Dataset Loss: 0.5521\n",
            "Iteration 79300, Dataset Loss: 0.5526\n",
            "Iteration 79400, Dataset Loss: 0.5525\n",
            "Iteration 79500, Dataset Loss: 0.5520\n",
            "Iteration 79600, Dataset Loss: 0.5521\n",
            "Iteration 79700, Dataset Loss: 0.5520\n",
            "Iteration 79800, Dataset Loss: 0.5522\n",
            "Iteration 79900, Dataset Loss: 0.5520\n",
            "Iteration 80000, Dataset Loss: 0.5524\n",
            "Iteration 80100, Dataset Loss: 0.5528\n",
            "Iteration 80200, Dataset Loss: 0.5521\n",
            "Iteration 80300, Dataset Loss: 0.5523\n",
            "Iteration 80400, Dataset Loss: 0.5520\n",
            "Iteration 80500, Dataset Loss: 0.5523\n",
            "Iteration 80600, Dataset Loss: 0.5522\n",
            "Iteration 80700, Dataset Loss: 0.5521\n",
            "Iteration 80800, Dataset Loss: 0.5530\n",
            "Iteration 80900, Dataset Loss: 0.5525\n",
            "Iteration 81000, Dataset Loss: 0.5522\n",
            "Iteration 81100, Dataset Loss: 0.5520\n",
            "Iteration 81200, Dataset Loss: 0.5520\n",
            "Iteration 81300, Dataset Loss: 0.5520\n",
            "Iteration 81400, Dataset Loss: 0.5520\n",
            "Iteration 81500, Dataset Loss: 0.5521\n",
            "Iteration 81600, Dataset Loss: 0.5520\n",
            "Iteration 81700, Dataset Loss: 0.5521\n",
            "Iteration 81800, Dataset Loss: 0.5521\n",
            "Iteration 81900, Dataset Loss: 0.5521\n",
            "Iteration 82000, Dataset Loss: 0.5520\n",
            "Iteration 82100, Dataset Loss: 0.5521\n",
            "Iteration 82200, Dataset Loss: 0.5520\n",
            "Iteration 82300, Dataset Loss: 0.5520\n",
            "Iteration 82400, Dataset Loss: 0.5520\n",
            "Iteration 82500, Dataset Loss: 0.5520\n",
            "Iteration 82600, Dataset Loss: 0.5520\n",
            "Iteration 82700, Dataset Loss: 0.5521\n",
            "Iteration 82800, Dataset Loss: 0.5521\n",
            "Iteration 82900, Dataset Loss: 0.5521\n",
            "Iteration 83000, Dataset Loss: 0.5520\n",
            "Iteration 83100, Dataset Loss: 0.5520\n",
            "Iteration 83200, Dataset Loss: 0.5521\n",
            "Iteration 83300, Dataset Loss: 0.5520\n",
            "Iteration 83400, Dataset Loss: 0.5521\n",
            "Iteration 83500, Dataset Loss: 0.5526\n",
            "Iteration 83600, Dataset Loss: 0.5527\n",
            "Iteration 83700, Dataset Loss: 0.5526\n",
            "Iteration 83800, Dataset Loss: 0.5530\n",
            "Iteration 83900, Dataset Loss: 0.5526\n",
            "Iteration 84000, Dataset Loss: 0.5525\n",
            "Iteration 84100, Dataset Loss: 0.5522\n",
            "Iteration 84200, Dataset Loss: 0.5521\n",
            "Iteration 84300, Dataset Loss: 0.5520\n",
            "Iteration 84400, Dataset Loss: 0.5526\n",
            "Iteration 84500, Dataset Loss: 0.5521\n",
            "Iteration 84600, Dataset Loss: 0.5521\n",
            "Iteration 84700, Dataset Loss: 0.5521\n",
            "Iteration 84800, Dataset Loss: 0.5520\n",
            "Iteration 84900, Dataset Loss: 0.5520\n",
            "Iteration 85000, Dataset Loss: 0.5520\n",
            "Iteration 85100, Dataset Loss: 0.5523\n",
            "Iteration 85200, Dataset Loss: 0.5529\n",
            "Iteration 85300, Dataset Loss: 0.5529\n",
            "Iteration 85400, Dataset Loss: 0.5520\n",
            "Iteration 85500, Dataset Loss: 0.5522\n",
            "Iteration 85600, Dataset Loss: 0.5526\n",
            "Iteration 85700, Dataset Loss: 0.5524\n",
            "Iteration 85800, Dataset Loss: 0.5522\n",
            "Iteration 85900, Dataset Loss: 0.5520\n",
            "Iteration 86000, Dataset Loss: 0.5521\n",
            "Iteration 86100, Dataset Loss: 0.5529\n",
            "Iteration 86200, Dataset Loss: 0.5533\n",
            "Iteration 86300, Dataset Loss: 0.5526\n",
            "Iteration 86400, Dataset Loss: 0.5529\n",
            "Iteration 86500, Dataset Loss: 0.5530\n",
            "Iteration 86600, Dataset Loss: 0.5526\n",
            "Iteration 86700, Dataset Loss: 0.5524\n",
            "Iteration 86800, Dataset Loss: 0.5520\n",
            "Iteration 86900, Dataset Loss: 0.5520\n",
            "Iteration 87000, Dataset Loss: 0.5520\n",
            "Iteration 87100, Dataset Loss: 0.5521\n",
            "Iteration 87200, Dataset Loss: 0.5520\n",
            "Iteration 87300, Dataset Loss: 0.5520\n",
            "Iteration 87400, Dataset Loss: 0.5520\n",
            "Iteration 87500, Dataset Loss: 0.5521\n",
            "Iteration 87600, Dataset Loss: 0.5523\n",
            "Iteration 87700, Dataset Loss: 0.5520\n",
            "Iteration 87800, Dataset Loss: 0.5521\n",
            "Iteration 87900, Dataset Loss: 0.5520\n",
            "Iteration 88000, Dataset Loss: 0.5521\n",
            "Iteration 88100, Dataset Loss: 0.5521\n",
            "Iteration 88200, Dataset Loss: 0.5521\n",
            "Iteration 88300, Dataset Loss: 0.5521\n",
            "Iteration 88400, Dataset Loss: 0.5521\n",
            "Iteration 88500, Dataset Loss: 0.5525\n",
            "Iteration 88600, Dataset Loss: 0.5522\n",
            "Iteration 88700, Dataset Loss: 0.5521\n",
            "Iteration 88800, Dataset Loss: 0.5521\n",
            "Iteration 88900, Dataset Loss: 0.5525\n",
            "Iteration 89000, Dataset Loss: 0.5525\n",
            "Iteration 89100, Dataset Loss: 0.5526\n",
            "Iteration 89200, Dataset Loss: 0.5527\n",
            "Iteration 89300, Dataset Loss: 0.5524\n",
            "Iteration 89400, Dataset Loss: 0.5520\n",
            "Iteration 89500, Dataset Loss: 0.5526\n",
            "Iteration 89600, Dataset Loss: 0.5521\n",
            "Iteration 89700, Dataset Loss: 0.5527\n",
            "Iteration 89800, Dataset Loss: 0.5523\n",
            "Iteration 89900, Dataset Loss: 0.5526\n",
            "Iteration 90000, Dataset Loss: 0.5520\n",
            "Iteration 90100, Dataset Loss: 0.5525\n",
            "Iteration 90200, Dataset Loss: 0.5522\n",
            "Iteration 90300, Dataset Loss: 0.5521\n",
            "Iteration 90400, Dataset Loss: 0.5520\n",
            "Iteration 90500, Dataset Loss: 0.5521\n",
            "Iteration 90600, Dataset Loss: 0.5523\n",
            "Iteration 90700, Dataset Loss: 0.5521\n",
            "Iteration 90800, Dataset Loss: 0.5520\n",
            "Iteration 90900, Dataset Loss: 0.5523\n",
            "Iteration 91000, Dataset Loss: 0.5521\n",
            "Iteration 91100, Dataset Loss: 0.5520\n",
            "Iteration 91200, Dataset Loss: 0.5521\n",
            "Iteration 91300, Dataset Loss: 0.5521\n",
            "Iteration 91400, Dataset Loss: 0.5521\n",
            "Iteration 91500, Dataset Loss: 0.5526\n",
            "Iteration 91600, Dataset Loss: 0.5524\n",
            "Iteration 91700, Dataset Loss: 0.5524\n",
            "Iteration 91800, Dataset Loss: 0.5522\n",
            "Iteration 91900, Dataset Loss: 0.5520\n",
            "Iteration 92000, Dataset Loss: 0.5520\n",
            "Iteration 92100, Dataset Loss: 0.5522\n",
            "Iteration 92200, Dataset Loss: 0.5525\n",
            "Iteration 92300, Dataset Loss: 0.5527\n",
            "Iteration 92400, Dataset Loss: 0.5525\n",
            "Iteration 92500, Dataset Loss: 0.5522\n",
            "Iteration 92600, Dataset Loss: 0.5520\n",
            "Iteration 92700, Dataset Loss: 0.5520\n",
            "Iteration 92800, Dataset Loss: 0.5520\n",
            "Iteration 92900, Dataset Loss: 0.5520\n",
            "Iteration 93000, Dataset Loss: 0.5522\n",
            "Iteration 93100, Dataset Loss: 0.5520\n",
            "Iteration 93200, Dataset Loss: 0.5520\n",
            "Iteration 93300, Dataset Loss: 0.5520\n",
            "Iteration 93400, Dataset Loss: 0.5521\n",
            "Iteration 93500, Dataset Loss: 0.5521\n",
            "Iteration 93600, Dataset Loss: 0.5522\n",
            "Iteration 93700, Dataset Loss: 0.5522\n",
            "Iteration 93800, Dataset Loss: 0.5520\n",
            "Iteration 93900, Dataset Loss: 0.5520\n",
            "Iteration 94000, Dataset Loss: 0.5524\n",
            "Iteration 94100, Dataset Loss: 0.5521\n",
            "Iteration 94200, Dataset Loss: 0.5524\n",
            "Iteration 94300, Dataset Loss: 0.5522\n",
            "Iteration 94400, Dataset Loss: 0.5521\n",
            "Iteration 94500, Dataset Loss: 0.5521\n",
            "Iteration 94600, Dataset Loss: 0.5521\n",
            "Iteration 94700, Dataset Loss: 0.5525\n",
            "Iteration 94800, Dataset Loss: 0.5521\n",
            "Iteration 94900, Dataset Loss: 0.5522\n",
            "Iteration 95000, Dataset Loss: 0.5523\n",
            "Iteration 95100, Dataset Loss: 0.5521\n",
            "Iteration 95200, Dataset Loss: 0.5522\n",
            "Iteration 95300, Dataset Loss: 0.5526\n",
            "Iteration 95400, Dataset Loss: 0.5526\n",
            "Iteration 95500, Dataset Loss: 0.5524\n",
            "Iteration 95600, Dataset Loss: 0.5527\n",
            "Iteration 95700, Dataset Loss: 0.5524\n",
            "Iteration 95800, Dataset Loss: 0.5522\n",
            "Iteration 95900, Dataset Loss: 0.5520\n",
            "Iteration 96000, Dataset Loss: 0.5522\n",
            "Iteration 96100, Dataset Loss: 0.5521\n",
            "Iteration 96200, Dataset Loss: 0.5521\n",
            "Iteration 96300, Dataset Loss: 0.5520\n",
            "Iteration 96400, Dataset Loss: 0.5524\n",
            "Iteration 96500, Dataset Loss: 0.5521\n",
            "Iteration 96600, Dataset Loss: 0.5521\n",
            "Iteration 96700, Dataset Loss: 0.5529\n",
            "Iteration 96800, Dataset Loss: 0.5527\n",
            "Iteration 96900, Dataset Loss: 0.5524\n",
            "Iteration 97000, Dataset Loss: 0.5522\n",
            "Iteration 97100, Dataset Loss: 0.5526\n",
            "Iteration 97200, Dataset Loss: 0.5520\n",
            "Iteration 97300, Dataset Loss: 0.5521\n",
            "Iteration 97400, Dataset Loss: 0.5521\n",
            "Iteration 97500, Dataset Loss: 0.5520\n",
            "Iteration 97600, Dataset Loss: 0.5521\n",
            "Iteration 97700, Dataset Loss: 0.5520\n",
            "Iteration 97800, Dataset Loss: 0.5522\n",
            "Iteration 97900, Dataset Loss: 0.5521\n",
            "Iteration 98000, Dataset Loss: 0.5520\n",
            "Iteration 98100, Dataset Loss: 0.5522\n",
            "Iteration 98200, Dataset Loss: 0.5529\n",
            "Iteration 98300, Dataset Loss: 0.5521\n",
            "Iteration 98400, Dataset Loss: 0.5521\n",
            "Iteration 98500, Dataset Loss: 0.5521\n",
            "Iteration 98600, Dataset Loss: 0.5520\n",
            "Iteration 98700, Dataset Loss: 0.5526\n",
            "Iteration 98800, Dataset Loss: 0.5522\n",
            "Iteration 98900, Dataset Loss: 0.5521\n",
            "Iteration 99000, Dataset Loss: 0.5527\n",
            "Iteration 99100, Dataset Loss: 0.5523\n",
            "Iteration 99200, Dataset Loss: 0.5524\n",
            "Iteration 99300, Dataset Loss: 0.5526\n",
            "Iteration 99400, Dataset Loss: 0.5521\n",
            "Iteration 99500, Dataset Loss: 0.5520\n",
            "Iteration 99600, Dataset Loss: 0.5521\n",
            "Iteration 99700, Dataset Loss: 0.5521\n",
            "Iteration 99800, Dataset Loss: 0.5528\n",
            "Iteration 99900, Dataset Loss: 0.5521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_arr = np.array(X_test)\n",
        "y_arr = np.array(y_test).reshape(1, -1)\n",
        "z1_test = np.dot(w1, X_arr.T) + b1\n",
        "a1_test = np.maximum(0, z1_test)\n",
        "z2_test = np.dot(w2, a1_test) + b2\n",
        "a2_test = np.maximum(0, z2_test)\n",
        "z3_test = np.dot(w3, a2_test) + b3\n",
        "z3_test = z3_test.astype(np.float64)\n",
        "y_hat_test = 1 / (1 + np.exp(-np.clip(z3_test, -500, 500)))\n",
        "\n",
        "y_pred = (y_hat_test >= 0.5).astype(int)\n",
        "accuracy = np.mean(y_pred == y_arr) * 100\n",
        "print(\"Case1: Raw data Accuracy-\", accuracy)"
      ],
      "metadata": {
        "id": "bvvj3NmUbKGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1235eb7b-310b-4238-bef9-417a11309e39"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case1: Raw data Accuracy- 76.3773723972729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case_2\n"
      ],
      "metadata": {
        "id": "_MeVEI94YMJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_min = X_train.min(axis=0)\n",
        "X_max = X_train.max(axis=0)\n",
        "X_testing = pd.DataFrame(X_test, columns=X_train.columns)\n",
        "X_train_scaled = (X_train - X_min) / (X_max - X_min + 1e-8)\n",
        "X_test_scaled  = (X_testing - X_min) / (X_max - X_min + 1e-8)"
      ],
      "metadata": {
        "id": "h1SncQIxXraV"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_input = X_train_scaled.shape[1]\n",
        "n_hidden1 = 64\n",
        "n_hidden2 = 32\n",
        "n_output = 1\n",
        "np.random.seed(42)\n",
        "\n",
        "w1s = np.random.randn(n_hidden1, n_input) * np.sqrt(2 / n_input)\n",
        "b1s = np.zeros((n_hidden1, 1))\n",
        "\n",
        "w2s = np.random.randn(n_hidden2, n_hidden1) * np.sqrt(2 / n_hidden1)\n",
        "b2s = np.zeros((n_hidden2, 1))\n",
        "w3s = np.random.randn(n_output, n_hidden2) * np.sqrt(2 / n_hidden2)\n",
        "b3s = np.zeros((n_output, 1))"
      ],
      "metadata": {
        "id": "omw8S4Q9_IaF"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "w1s,b1s,w2s,b2s,w3s,b3s=solution(X_train_scaled,y_train,w1s,b1s,w2s,b2s,w3s,b3s)\n"
      ],
      "metadata": {
        "id": "xfrYdUkBYT3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c269dad-dd6a-4840-d5af-1121574e300b"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Dataset Loss: 0.6049\n",
            "Iteration 100, Dataset Loss: 0.5487\n",
            "Iteration 200, Dataset Loss: 0.5058\n",
            "Iteration 300, Dataset Loss: 0.4688\n",
            "Iteration 400, Dataset Loss: 0.4539\n",
            "Iteration 500, Dataset Loss: 0.4294\n",
            "Iteration 600, Dataset Loss: 0.4373\n",
            "Iteration 700, Dataset Loss: 0.4099\n",
            "Iteration 800, Dataset Loss: 0.4074\n",
            "Iteration 900, Dataset Loss: 0.4376\n",
            "Iteration 1000, Dataset Loss: 0.4199\n",
            "Iteration 1100, Dataset Loss: 0.4042\n",
            "Iteration 1200, Dataset Loss: 0.3938\n",
            "Iteration 1300, Dataset Loss: 0.3904\n",
            "Iteration 1400, Dataset Loss: 0.3937\n",
            "Iteration 1500, Dataset Loss: 0.4004\n",
            "Iteration 1600, Dataset Loss: 0.4086\n",
            "Iteration 1700, Dataset Loss: 0.3958\n",
            "Iteration 1800, Dataset Loss: 0.3879\n",
            "Iteration 1900, Dataset Loss: 0.4041\n",
            "Iteration 2000, Dataset Loss: 0.4079\n",
            "Iteration 2100, Dataset Loss: 0.4137\n",
            "Iteration 2200, Dataset Loss: 0.3842\n",
            "Iteration 2300, Dataset Loss: 0.3853\n",
            "Iteration 2400, Dataset Loss: 0.3826\n",
            "Iteration 2500, Dataset Loss: 0.3901\n",
            "Iteration 2600, Dataset Loss: 0.3824\n",
            "Iteration 2700, Dataset Loss: 0.3893\n",
            "Iteration 2800, Dataset Loss: 0.3842\n",
            "Iteration 2900, Dataset Loss: 0.3869\n",
            "Iteration 3000, Dataset Loss: 0.4035\n",
            "Iteration 3100, Dataset Loss: 0.3883\n",
            "Iteration 3200, Dataset Loss: 0.3863\n",
            "Iteration 3300, Dataset Loss: 0.3768\n",
            "Iteration 3400, Dataset Loss: 0.3724\n",
            "Iteration 3500, Dataset Loss: 0.4154\n",
            "Iteration 3600, Dataset Loss: 0.3802\n",
            "Iteration 3700, Dataset Loss: 0.3710\n",
            "Iteration 3800, Dataset Loss: 0.3719\n",
            "Iteration 3900, Dataset Loss: 0.3768\n",
            "Iteration 4000, Dataset Loss: 0.3763\n",
            "Iteration 4100, Dataset Loss: 0.3754\n",
            "Iteration 4200, Dataset Loss: 0.3911\n",
            "Iteration 4300, Dataset Loss: 0.3776\n",
            "Iteration 4400, Dataset Loss: 0.3866\n",
            "Iteration 4500, Dataset Loss: 0.3775\n",
            "Iteration 4600, Dataset Loss: 0.3726\n",
            "Iteration 4700, Dataset Loss: 0.3707\n",
            "Iteration 4800, Dataset Loss: 0.3833\n",
            "Iteration 4900, Dataset Loss: 0.3750\n",
            "Iteration 5000, Dataset Loss: 0.3669\n",
            "Iteration 5100, Dataset Loss: 0.3659\n",
            "Iteration 5200, Dataset Loss: 0.3653\n",
            "Iteration 5300, Dataset Loss: 0.3689\n",
            "Iteration 5400, Dataset Loss: 0.3857\n",
            "Iteration 5500, Dataset Loss: 0.3732\n",
            "Iteration 5600, Dataset Loss: 0.3610\n",
            "Iteration 5700, Dataset Loss: 0.3677\n",
            "Iteration 5800, Dataset Loss: 0.3771\n",
            "Iteration 5900, Dataset Loss: 0.4138\n",
            "Iteration 6000, Dataset Loss: 0.3706\n",
            "Iteration 6100, Dataset Loss: 0.3942\n",
            "Iteration 6200, Dataset Loss: 0.3825\n",
            "Iteration 6300, Dataset Loss: 0.3714\n",
            "Iteration 6400, Dataset Loss: 0.3641\n",
            "Iteration 6500, Dataset Loss: 0.3927\n",
            "Iteration 6600, Dataset Loss: 0.3692\n",
            "Iteration 6700, Dataset Loss: 0.3619\n",
            "Iteration 6800, Dataset Loss: 0.3627\n",
            "Iteration 6900, Dataset Loss: 0.3603\n",
            "Iteration 7000, Dataset Loss: 0.3874\n",
            "Iteration 7100, Dataset Loss: 0.3609\n",
            "Iteration 7200, Dataset Loss: 0.3650\n",
            "Iteration 7300, Dataset Loss: 0.3617\n",
            "Iteration 7400, Dataset Loss: 0.3719\n",
            "Iteration 7500, Dataset Loss: 0.3689\n",
            "Iteration 7600, Dataset Loss: 0.3612\n",
            "Iteration 7700, Dataset Loss: 0.3700\n",
            "Iteration 7800, Dataset Loss: 0.3675\n",
            "Iteration 7900, Dataset Loss: 0.3596\n",
            "Iteration 8000, Dataset Loss: 0.3616\n",
            "Iteration 8100, Dataset Loss: 0.3745\n",
            "Iteration 8200, Dataset Loss: 0.3657\n",
            "Iteration 8300, Dataset Loss: 0.3734\n",
            "Iteration 8400, Dataset Loss: 0.3731\n",
            "Iteration 8500, Dataset Loss: 0.3611\n",
            "Iteration 8600, Dataset Loss: 0.3730\n",
            "Iteration 8700, Dataset Loss: 0.3787\n",
            "Iteration 8800, Dataset Loss: 0.3547\n",
            "Iteration 8900, Dataset Loss: 0.3692\n",
            "Iteration 9000, Dataset Loss: 0.3685\n",
            "Iteration 9100, Dataset Loss: 0.3622\n",
            "Iteration 9200, Dataset Loss: 0.3553\n",
            "Iteration 9300, Dataset Loss: 0.3585\n",
            "Iteration 9400, Dataset Loss: 0.3554\n",
            "Iteration 9500, Dataset Loss: 0.3571\n",
            "Iteration 9600, Dataset Loss: 0.3573\n",
            "Iteration 9700, Dataset Loss: 0.3569\n",
            "Iteration 9800, Dataset Loss: 0.3612\n",
            "Iteration 9900, Dataset Loss: 0.3690\n",
            "Iteration 10000, Dataset Loss: 0.3619\n",
            "Iteration 10100, Dataset Loss: 0.3719\n",
            "Iteration 10200, Dataset Loss: 0.3547\n",
            "Iteration 10300, Dataset Loss: 0.3588\n",
            "Iteration 10400, Dataset Loss: 0.3679\n",
            "Iteration 10500, Dataset Loss: 0.3569\n",
            "Iteration 10600, Dataset Loss: 0.3575\n",
            "Iteration 10700, Dataset Loss: 0.3602\n",
            "Iteration 10800, Dataset Loss: 0.3678\n",
            "Iteration 10900, Dataset Loss: 0.3690\n",
            "Iteration 11000, Dataset Loss: 0.3753\n",
            "Iteration 11100, Dataset Loss: 0.3586\n",
            "Iteration 11200, Dataset Loss: 0.3679\n",
            "Iteration 11300, Dataset Loss: 0.3587\n",
            "Iteration 11400, Dataset Loss: 0.3546\n",
            "Iteration 11500, Dataset Loss: 0.3557\n",
            "Iteration 11600, Dataset Loss: 0.3576\n",
            "Iteration 11700, Dataset Loss: 0.3726\n",
            "Iteration 11800, Dataset Loss: 0.3550\n",
            "Iteration 11900, Dataset Loss: 0.3615\n",
            "Iteration 12000, Dataset Loss: 0.3578\n",
            "Iteration 12100, Dataset Loss: 0.3582\n",
            "Iteration 12200, Dataset Loss: 0.3612\n",
            "Iteration 12300, Dataset Loss: 0.3538\n",
            "Iteration 12400, Dataset Loss: 0.3605\n",
            "Iteration 12500, Dataset Loss: 0.3552\n",
            "Iteration 12600, Dataset Loss: 0.3622\n",
            "Iteration 12700, Dataset Loss: 0.3632\n",
            "Iteration 12800, Dataset Loss: 0.3787\n",
            "Iteration 12900, Dataset Loss: 0.3576\n",
            "Iteration 13000, Dataset Loss: 0.3531\n",
            "Iteration 13100, Dataset Loss: 0.3547\n",
            "Iteration 13200, Dataset Loss: 0.3591\n",
            "Iteration 13300, Dataset Loss: 0.3617\n",
            "Iteration 13400, Dataset Loss: 0.3588\n",
            "Iteration 13500, Dataset Loss: 0.3579\n",
            "Iteration 13600, Dataset Loss: 0.3575\n",
            "Iteration 13700, Dataset Loss: 0.3535\n",
            "Iteration 13800, Dataset Loss: 0.3635\n",
            "Iteration 13900, Dataset Loss: 0.3581\n",
            "Iteration 14000, Dataset Loss: 0.3675\n",
            "Iteration 14100, Dataset Loss: 0.3607\n",
            "Iteration 14200, Dataset Loss: 0.3656\n",
            "Iteration 14300, Dataset Loss: 0.3598\n",
            "Iteration 14400, Dataset Loss: 0.3588\n",
            "Iteration 14500, Dataset Loss: 0.3961\n",
            "Iteration 14600, Dataset Loss: 0.3648\n",
            "Iteration 14700, Dataset Loss: 0.3557\n",
            "Iteration 14800, Dataset Loss: 0.3563\n",
            "Iteration 14900, Dataset Loss: 0.3564\n",
            "Iteration 15000, Dataset Loss: 0.3605\n",
            "Iteration 15100, Dataset Loss: 0.3784\n",
            "Iteration 15200, Dataset Loss: 0.3528\n",
            "Iteration 15300, Dataset Loss: 0.3542\n",
            "Iteration 15400, Dataset Loss: 0.3527\n",
            "Iteration 15500, Dataset Loss: 0.3512\n",
            "Iteration 15600, Dataset Loss: 0.3555\n",
            "Iteration 15700, Dataset Loss: 0.3512\n",
            "Iteration 15800, Dataset Loss: 0.3552\n",
            "Iteration 15900, Dataset Loss: 0.3719\n",
            "Iteration 16000, Dataset Loss: 0.3902\n",
            "Iteration 16100, Dataset Loss: 0.3558\n",
            "Iteration 16200, Dataset Loss: 0.3549\n",
            "Iteration 16300, Dataset Loss: 0.3545\n",
            "Iteration 16400, Dataset Loss: 0.3532\n",
            "Iteration 16500, Dataset Loss: 0.3557\n",
            "Iteration 16600, Dataset Loss: 0.3659\n",
            "Iteration 16700, Dataset Loss: 0.3551\n",
            "Iteration 16800, Dataset Loss: 0.3524\n",
            "Iteration 16900, Dataset Loss: 0.3571\n",
            "Iteration 17000, Dataset Loss: 0.3570\n",
            "Iteration 17100, Dataset Loss: 0.3547\n",
            "Iteration 17200, Dataset Loss: 0.3555\n",
            "Iteration 17300, Dataset Loss: 0.3549\n",
            "Iteration 17400, Dataset Loss: 0.3525\n",
            "Iteration 17500, Dataset Loss: 0.3529\n",
            "Iteration 17600, Dataset Loss: 0.3526\n",
            "Iteration 17700, Dataset Loss: 0.3565\n",
            "Iteration 17800, Dataset Loss: 0.3557\n",
            "Iteration 17900, Dataset Loss: 0.3861\n",
            "Iteration 18000, Dataset Loss: 0.3523\n",
            "Iteration 18100, Dataset Loss: 0.3491\n",
            "Iteration 18200, Dataset Loss: 0.3583\n",
            "Iteration 18300, Dataset Loss: 0.3511\n",
            "Iteration 18400, Dataset Loss: 0.3526\n",
            "Iteration 18500, Dataset Loss: 0.3544\n",
            "Iteration 18600, Dataset Loss: 0.3581\n",
            "Iteration 18700, Dataset Loss: 0.3495\n",
            "Iteration 18800, Dataset Loss: 0.3589\n",
            "Iteration 18900, Dataset Loss: 0.3488\n",
            "Iteration 19000, Dataset Loss: 0.3485\n",
            "Iteration 19100, Dataset Loss: 0.3687\n",
            "Iteration 19200, Dataset Loss: 0.3522\n",
            "Iteration 19300, Dataset Loss: 0.3551\n",
            "Iteration 19400, Dataset Loss: 0.3479\n",
            "Iteration 19500, Dataset Loss: 0.3518\n",
            "Iteration 19600, Dataset Loss: 0.3473\n",
            "Iteration 19700, Dataset Loss: 0.3518\n",
            "Iteration 19800, Dataset Loss: 0.3547\n",
            "Iteration 19900, Dataset Loss: 0.3544\n",
            "Iteration 20000, Dataset Loss: 0.3646\n",
            "Iteration 20100, Dataset Loss: 0.3640\n",
            "Iteration 20200, Dataset Loss: 0.3480\n",
            "Iteration 20300, Dataset Loss: 0.3612\n",
            "Iteration 20400, Dataset Loss: 0.3486\n",
            "Iteration 20500, Dataset Loss: 0.3484\n",
            "Iteration 20600, Dataset Loss: 0.3466\n",
            "Iteration 20700, Dataset Loss: 0.3487\n",
            "Iteration 20800, Dataset Loss: 0.3493\n",
            "Iteration 20900, Dataset Loss: 0.3480\n",
            "Iteration 21000, Dataset Loss: 0.3507\n",
            "Iteration 21100, Dataset Loss: 0.3478\n",
            "Iteration 21200, Dataset Loss: 0.3470\n",
            "Iteration 21300, Dataset Loss: 0.3494\n",
            "Iteration 21400, Dataset Loss: 0.3518\n",
            "Iteration 21500, Dataset Loss: 0.3608\n",
            "Iteration 21600, Dataset Loss: 0.3494\n",
            "Iteration 21700, Dataset Loss: 0.3508\n",
            "Iteration 21800, Dataset Loss: 0.3477\n",
            "Iteration 21900, Dataset Loss: 0.3461\n",
            "Iteration 22000, Dataset Loss: 0.3503\n",
            "Iteration 22100, Dataset Loss: 0.3466\n",
            "Iteration 22200, Dataset Loss: 0.3637\n",
            "Iteration 22300, Dataset Loss: 0.3503\n",
            "Iteration 22400, Dataset Loss: 0.3460\n",
            "Iteration 22500, Dataset Loss: 0.3451\n",
            "Iteration 22600, Dataset Loss: 0.3456\n",
            "Iteration 22700, Dataset Loss: 0.3463\n",
            "Iteration 22800, Dataset Loss: 0.3493\n",
            "Iteration 22900, Dataset Loss: 0.3452\n",
            "Iteration 23000, Dataset Loss: 0.3549\n",
            "Iteration 23100, Dataset Loss: 0.3492\n",
            "Iteration 23200, Dataset Loss: 0.3472\n",
            "Iteration 23300, Dataset Loss: 0.3466\n",
            "Iteration 23400, Dataset Loss: 0.3472\n",
            "Iteration 23500, Dataset Loss: 0.3868\n",
            "Iteration 23600, Dataset Loss: 0.3471\n",
            "Iteration 23700, Dataset Loss: 0.3460\n",
            "Iteration 23800, Dataset Loss: 0.3463\n",
            "Iteration 23900, Dataset Loss: 0.3516\n",
            "Iteration 24000, Dataset Loss: 0.3459\n",
            "Iteration 24100, Dataset Loss: 0.3585\n",
            "Iteration 24200, Dataset Loss: 0.3448\n",
            "Iteration 24300, Dataset Loss: 0.3606\n",
            "Iteration 24400, Dataset Loss: 0.3800\n",
            "Iteration 24500, Dataset Loss: 0.3477\n",
            "Iteration 24600, Dataset Loss: 0.3491\n",
            "Iteration 24700, Dataset Loss: 0.3557\n",
            "Iteration 24800, Dataset Loss: 0.3673\n",
            "Iteration 24900, Dataset Loss: 0.3531\n",
            "Iteration 25000, Dataset Loss: 0.3449\n",
            "Iteration 25100, Dataset Loss: 0.3504\n",
            "Iteration 25200, Dataset Loss: 0.3489\n",
            "Iteration 25300, Dataset Loss: 0.3515\n",
            "Iteration 25400, Dataset Loss: 0.3531\n",
            "Iteration 25500, Dataset Loss: 0.3545\n",
            "Iteration 25600, Dataset Loss: 0.3642\n",
            "Iteration 25700, Dataset Loss: 0.3476\n",
            "Iteration 25800, Dataset Loss: 0.3480\n",
            "Iteration 25900, Dataset Loss: 0.3480\n",
            "Iteration 26000, Dataset Loss: 0.3566\n",
            "Iteration 26100, Dataset Loss: 0.3441\n",
            "Iteration 26200, Dataset Loss: 0.3460\n",
            "Iteration 26300, Dataset Loss: 0.3499\n",
            "Iteration 26400, Dataset Loss: 0.3460\n",
            "Iteration 26500, Dataset Loss: 0.3553\n",
            "Iteration 26600, Dataset Loss: 0.3481\n",
            "Iteration 26700, Dataset Loss: 0.3526\n",
            "Iteration 26800, Dataset Loss: 0.3443\n",
            "Iteration 26900, Dataset Loss: 0.3481\n",
            "Iteration 27000, Dataset Loss: 0.3544\n",
            "Iteration 27100, Dataset Loss: 0.3512\n",
            "Iteration 27200, Dataset Loss: 0.3609\n",
            "Iteration 27300, Dataset Loss: 0.3556\n",
            "Iteration 27400, Dataset Loss: 0.3485\n",
            "Iteration 27500, Dataset Loss: 0.3452\n",
            "Iteration 27600, Dataset Loss: 0.3661\n",
            "Iteration 27700, Dataset Loss: 0.3468\n",
            "Iteration 27800, Dataset Loss: 0.3554\n",
            "Iteration 27900, Dataset Loss: 0.3516\n",
            "Iteration 28000, Dataset Loss: 0.3630\n",
            "Iteration 28100, Dataset Loss: 0.3595\n",
            "Iteration 28200, Dataset Loss: 0.3459\n",
            "Iteration 28300, Dataset Loss: 0.3493\n",
            "Iteration 28400, Dataset Loss: 0.3459\n",
            "Iteration 28500, Dataset Loss: 0.3461\n",
            "Iteration 28600, Dataset Loss: 0.3697\n",
            "Iteration 28700, Dataset Loss: 0.3510\n",
            "Iteration 28800, Dataset Loss: 0.3493\n",
            "Iteration 28900, Dataset Loss: 0.3481\n",
            "Iteration 29000, Dataset Loss: 0.3497\n",
            "Iteration 29100, Dataset Loss: 0.3801\n",
            "Iteration 29200, Dataset Loss: 0.3461\n",
            "Iteration 29300, Dataset Loss: 0.3489\n",
            "Iteration 29400, Dataset Loss: 0.3635\n",
            "Iteration 29500, Dataset Loss: 0.3598\n",
            "Iteration 29600, Dataset Loss: 0.3452\n",
            "Iteration 29700, Dataset Loss: 0.3627\n",
            "Iteration 29800, Dataset Loss: 0.3546\n",
            "Iteration 29900, Dataset Loss: 0.3445\n",
            "Iteration 30000, Dataset Loss: 0.3435\n",
            "Iteration 30100, Dataset Loss: 0.3533\n",
            "Iteration 30200, Dataset Loss: 0.3425\n",
            "Iteration 30300, Dataset Loss: 0.3785\n",
            "Iteration 30400, Dataset Loss: 0.3480\n",
            "Iteration 30500, Dataset Loss: 0.3636\n",
            "Iteration 30600, Dataset Loss: 0.3474\n",
            "Iteration 30700, Dataset Loss: 0.3454\n",
            "Iteration 30800, Dataset Loss: 0.3477\n",
            "Iteration 30900, Dataset Loss: 0.3455\n",
            "Iteration 31000, Dataset Loss: 0.3469\n",
            "Iteration 31100, Dataset Loss: 0.3423\n",
            "Iteration 31200, Dataset Loss: 0.3749\n",
            "Iteration 31300, Dataset Loss: 0.3432\n",
            "Iteration 31400, Dataset Loss: 0.3463\n",
            "Iteration 31500, Dataset Loss: 0.3566\n",
            "Iteration 31600, Dataset Loss: 0.3432\n",
            "Iteration 31700, Dataset Loss: 0.3442\n",
            "Iteration 31800, Dataset Loss: 0.3589\n",
            "Iteration 31900, Dataset Loss: 0.3535\n",
            "Iteration 32000, Dataset Loss: 0.3485\n",
            "Iteration 32100, Dataset Loss: 0.3498\n",
            "Iteration 32200, Dataset Loss: 0.3425\n",
            "Iteration 32300, Dataset Loss: 0.3409\n",
            "Iteration 32400, Dataset Loss: 0.3409\n",
            "Iteration 32500, Dataset Loss: 0.3408\n",
            "Iteration 32600, Dataset Loss: 0.3622\n",
            "Iteration 32700, Dataset Loss: 0.3441\n",
            "Iteration 32800, Dataset Loss: 0.3450\n",
            "Iteration 32900, Dataset Loss: 0.3474\n",
            "Iteration 33000, Dataset Loss: 0.3471\n",
            "Iteration 33100, Dataset Loss: 0.3417\n",
            "Iteration 33200, Dataset Loss: 0.3442\n",
            "Iteration 33300, Dataset Loss: 0.3576\n",
            "Iteration 33400, Dataset Loss: 0.3411\n",
            "Iteration 33500, Dataset Loss: 0.3415\n",
            "Iteration 33600, Dataset Loss: 0.3411\n",
            "Iteration 33700, Dataset Loss: 0.3418\n",
            "Iteration 33800, Dataset Loss: 0.3643\n",
            "Iteration 33900, Dataset Loss: 0.3445\n",
            "Iteration 34000, Dataset Loss: 0.3531\n",
            "Iteration 34100, Dataset Loss: 0.3486\n",
            "Iteration 34200, Dataset Loss: 0.3446\n",
            "Iteration 34300, Dataset Loss: 0.3431\n",
            "Iteration 34400, Dataset Loss: 0.3423\n",
            "Iteration 34500, Dataset Loss: 0.3445\n",
            "Iteration 34600, Dataset Loss: 0.3456\n",
            "Iteration 34700, Dataset Loss: 0.3428\n",
            "Iteration 34800, Dataset Loss: 0.3465\n",
            "Iteration 34900, Dataset Loss: 0.3470\n",
            "Iteration 35000, Dataset Loss: 0.3447\n",
            "Iteration 35100, Dataset Loss: 0.3464\n",
            "Iteration 35200, Dataset Loss: 0.3784\n",
            "Iteration 35300, Dataset Loss: 0.3598\n",
            "Iteration 35400, Dataset Loss: 0.3447\n",
            "Iteration 35500, Dataset Loss: 0.3413\n",
            "Iteration 35600, Dataset Loss: 0.3561\n",
            "Iteration 35700, Dataset Loss: 0.3782\n",
            "Iteration 35800, Dataset Loss: 0.3428\n",
            "Iteration 35900, Dataset Loss: 0.3449\n",
            "Iteration 36000, Dataset Loss: 0.3457\n",
            "Iteration 36100, Dataset Loss: 0.3426\n",
            "Iteration 36200, Dataset Loss: 0.3487\n",
            "Iteration 36300, Dataset Loss: 0.3479\n",
            "Iteration 36400, Dataset Loss: 0.3555\n",
            "Iteration 36500, Dataset Loss: 0.3481\n",
            "Iteration 36600, Dataset Loss: 0.3411\n",
            "Iteration 36700, Dataset Loss: 0.3418\n",
            "Iteration 36800, Dataset Loss: 0.3410\n",
            "Iteration 36900, Dataset Loss: 0.3411\n",
            "Iteration 37000, Dataset Loss: 0.3508\n",
            "Iteration 37100, Dataset Loss: 0.3428\n",
            "Iteration 37200, Dataset Loss: 0.3444\n",
            "Iteration 37300, Dataset Loss: 0.3400\n",
            "Iteration 37400, Dataset Loss: 0.3530\n",
            "Iteration 37500, Dataset Loss: 0.3480\n",
            "Iteration 37600, Dataset Loss: 0.3533\n",
            "Iteration 37700, Dataset Loss: 0.3551\n",
            "Iteration 37800, Dataset Loss: 0.3451\n",
            "Iteration 37900, Dataset Loss: 0.3448\n",
            "Iteration 38000, Dataset Loss: 0.3469\n",
            "Iteration 38100, Dataset Loss: 0.3435\n",
            "Iteration 38200, Dataset Loss: 0.3533\n",
            "Iteration 38300, Dataset Loss: 0.3448\n",
            "Iteration 38400, Dataset Loss: 0.3410\n",
            "Iteration 38500, Dataset Loss: 0.3509\n",
            "Iteration 38600, Dataset Loss: 0.3456\n",
            "Iteration 38700, Dataset Loss: 0.3441\n",
            "Iteration 38800, Dataset Loss: 0.3610\n",
            "Iteration 38900, Dataset Loss: 0.3478\n",
            "Iteration 39000, Dataset Loss: 0.3429\n",
            "Iteration 39100, Dataset Loss: 0.3622\n",
            "Iteration 39200, Dataset Loss: 0.3398\n",
            "Iteration 39300, Dataset Loss: 0.3543\n",
            "Iteration 39400, Dataset Loss: 0.3544\n",
            "Iteration 39500, Dataset Loss: 0.3458\n",
            "Iteration 39600, Dataset Loss: 0.3742\n",
            "Iteration 39700, Dataset Loss: 0.3428\n",
            "Iteration 39800, Dataset Loss: 0.3410\n",
            "Iteration 39900, Dataset Loss: 0.3645\n",
            "Iteration 40000, Dataset Loss: 0.3471\n",
            "Iteration 40100, Dataset Loss: 0.3438\n",
            "Iteration 40200, Dataset Loss: 0.3423\n",
            "Iteration 40300, Dataset Loss: 0.3453\n",
            "Iteration 40400, Dataset Loss: 0.3424\n",
            "Iteration 40500, Dataset Loss: 0.3413\n",
            "Iteration 40600, Dataset Loss: 0.3460\n",
            "Iteration 40700, Dataset Loss: 0.3454\n",
            "Iteration 40800, Dataset Loss: 0.3405\n",
            "Iteration 40900, Dataset Loss: 0.3419\n",
            "Iteration 41000, Dataset Loss: 0.3416\n",
            "Iteration 41100, Dataset Loss: 0.3390\n",
            "Iteration 41200, Dataset Loss: 0.3420\n",
            "Iteration 41300, Dataset Loss: 0.3553\n",
            "Iteration 41400, Dataset Loss: 0.3405\n",
            "Iteration 41500, Dataset Loss: 0.3646\n",
            "Iteration 41600, Dataset Loss: 0.3473\n",
            "Iteration 41700, Dataset Loss: 0.3414\n",
            "Iteration 41800, Dataset Loss: 0.3465\n",
            "Iteration 41900, Dataset Loss: 0.3417\n",
            "Iteration 42000, Dataset Loss: 0.3393\n",
            "Iteration 42100, Dataset Loss: 0.3397\n",
            "Iteration 42200, Dataset Loss: 0.3749\n",
            "Iteration 42300, Dataset Loss: 0.3459\n",
            "Iteration 42400, Dataset Loss: 0.3511\n",
            "Iteration 42500, Dataset Loss: 0.3375\n",
            "Iteration 42600, Dataset Loss: 0.3400\n",
            "Iteration 42700, Dataset Loss: 0.3656\n",
            "Iteration 42800, Dataset Loss: 0.3409\n",
            "Iteration 42900, Dataset Loss: 0.3425\n",
            "Iteration 43000, Dataset Loss: 0.3503\n",
            "Iteration 43100, Dataset Loss: 0.3454\n",
            "Iteration 43200, Dataset Loss: 0.3412\n",
            "Iteration 43300, Dataset Loss: 0.3397\n",
            "Iteration 43400, Dataset Loss: 0.3573\n",
            "Iteration 43500, Dataset Loss: 0.3444\n",
            "Iteration 43600, Dataset Loss: 0.3420\n",
            "Iteration 43700, Dataset Loss: 0.3408\n",
            "Iteration 43800, Dataset Loss: 0.3449\n",
            "Iteration 43900, Dataset Loss: 0.3605\n",
            "Iteration 44000, Dataset Loss: 0.3538\n",
            "Iteration 44100, Dataset Loss: 0.3508\n",
            "Iteration 44200, Dataset Loss: 0.3465\n",
            "Iteration 44300, Dataset Loss: 0.3512\n",
            "Iteration 44400, Dataset Loss: 0.3431\n",
            "Iteration 44500, Dataset Loss: 0.3443\n",
            "Iteration 44600, Dataset Loss: 0.3401\n",
            "Iteration 44700, Dataset Loss: 0.3429\n",
            "Iteration 44800, Dataset Loss: 0.3417\n",
            "Iteration 44900, Dataset Loss: 0.3442\n",
            "Iteration 45000, Dataset Loss: 0.3411\n",
            "Iteration 45100, Dataset Loss: 0.3427\n",
            "Iteration 45200, Dataset Loss: 0.3409\n",
            "Iteration 45300, Dataset Loss: 0.3452\n",
            "Iteration 45400, Dataset Loss: 0.3421\n",
            "Iteration 45500, Dataset Loss: 0.3427\n",
            "Iteration 45600, Dataset Loss: 0.3413\n",
            "Iteration 45700, Dataset Loss: 0.3441\n",
            "Iteration 45800, Dataset Loss: 0.3428\n",
            "Iteration 45900, Dataset Loss: 0.3470\n",
            "Iteration 46000, Dataset Loss: 0.3423\n",
            "Iteration 46100, Dataset Loss: 0.3451\n",
            "Iteration 46200, Dataset Loss: 0.3427\n",
            "Iteration 46300, Dataset Loss: 0.3499\n",
            "Iteration 46400, Dataset Loss: 0.3419\n",
            "Iteration 46500, Dataset Loss: 0.3400\n",
            "Iteration 46600, Dataset Loss: 0.3429\n",
            "Iteration 46700, Dataset Loss: 0.3689\n",
            "Iteration 46800, Dataset Loss: 0.3457\n",
            "Iteration 46900, Dataset Loss: 0.3399\n",
            "Iteration 47000, Dataset Loss: 0.3428\n",
            "Iteration 47100, Dataset Loss: 0.3386\n",
            "Iteration 47200, Dataset Loss: 0.3381\n",
            "Iteration 47300, Dataset Loss: 0.3390\n",
            "Iteration 47400, Dataset Loss: 0.3522\n",
            "Iteration 47500, Dataset Loss: 0.3437\n",
            "Iteration 47600, Dataset Loss: 0.3423\n",
            "Iteration 47700, Dataset Loss: 0.3505\n",
            "Iteration 47800, Dataset Loss: 0.3456\n",
            "Iteration 47900, Dataset Loss: 0.3393\n",
            "Iteration 48000, Dataset Loss: 0.3496\n",
            "Iteration 48100, Dataset Loss: 0.3402\n",
            "Iteration 48200, Dataset Loss: 0.3440\n",
            "Iteration 48300, Dataset Loss: 0.3473\n",
            "Iteration 48400, Dataset Loss: 0.3386\n",
            "Iteration 48500, Dataset Loss: 0.3507\n",
            "Iteration 48600, Dataset Loss: 0.3404\n",
            "Iteration 48700, Dataset Loss: 0.3589\n",
            "Iteration 48800, Dataset Loss: 0.3549\n",
            "Iteration 48900, Dataset Loss: 0.3450\n",
            "Iteration 49000, Dataset Loss: 0.3547\n",
            "Iteration 49100, Dataset Loss: 0.3474\n",
            "Iteration 49200, Dataset Loss: 0.3509\n",
            "Iteration 49300, Dataset Loss: 0.3417\n",
            "Iteration 49400, Dataset Loss: 0.3460\n",
            "Iteration 49500, Dataset Loss: 0.3397\n",
            "Iteration 49600, Dataset Loss: 0.3398\n",
            "Iteration 49700, Dataset Loss: 0.3411\n",
            "Iteration 49800, Dataset Loss: 0.3468\n",
            "Iteration 49900, Dataset Loss: 0.3744\n",
            "Iteration 50000, Dataset Loss: 0.3425\n",
            "Iteration 50100, Dataset Loss: 0.3399\n",
            "Iteration 50200, Dataset Loss: 0.3436\n",
            "Iteration 50300, Dataset Loss: 0.3438\n",
            "Iteration 50400, Dataset Loss: 0.3420\n",
            "Iteration 50500, Dataset Loss: 0.3397\n",
            "Iteration 50600, Dataset Loss: 0.3406\n",
            "Iteration 50700, Dataset Loss: 0.3444\n",
            "Iteration 50800, Dataset Loss: 0.3398\n",
            "Iteration 50900, Dataset Loss: 0.3416\n",
            "Iteration 51000, Dataset Loss: 0.3439\n",
            "Iteration 51100, Dataset Loss: 0.3546\n",
            "Iteration 51200, Dataset Loss: 0.3406\n",
            "Iteration 51300, Dataset Loss: 0.3398\n",
            "Iteration 51400, Dataset Loss: 0.3378\n",
            "Iteration 51500, Dataset Loss: 0.3347\n",
            "Iteration 51600, Dataset Loss: 0.3643\n",
            "Iteration 51700, Dataset Loss: 0.3475\n",
            "Iteration 51800, Dataset Loss: 0.3487\n",
            "Iteration 51900, Dataset Loss: 0.3371\n",
            "Iteration 52000, Dataset Loss: 0.3381\n",
            "Iteration 52100, Dataset Loss: 0.3447\n",
            "Iteration 52200, Dataset Loss: 0.3449\n",
            "Iteration 52300, Dataset Loss: 0.3397\n",
            "Iteration 52400, Dataset Loss: 0.3361\n",
            "Iteration 52500, Dataset Loss: 0.3456\n",
            "Iteration 52600, Dataset Loss: 0.3522\n",
            "Iteration 52700, Dataset Loss: 0.3456\n",
            "Iteration 52800, Dataset Loss: 0.3452\n",
            "Iteration 52900, Dataset Loss: 0.3462\n",
            "Iteration 53000, Dataset Loss: 0.3430\n",
            "Iteration 53100, Dataset Loss: 0.3372\n",
            "Iteration 53200, Dataset Loss: 0.3378\n",
            "Iteration 53300, Dataset Loss: 0.3569\n",
            "Iteration 53400, Dataset Loss: 0.3427\n",
            "Iteration 53500, Dataset Loss: 0.3408\n",
            "Iteration 53600, Dataset Loss: 0.3369\n",
            "Iteration 53700, Dataset Loss: 0.3526\n",
            "Iteration 53800, Dataset Loss: 0.3512\n",
            "Iteration 53900, Dataset Loss: 0.3454\n",
            "Iteration 54000, Dataset Loss: 0.3397\n",
            "Iteration 54100, Dataset Loss: 0.3371\n",
            "Iteration 54200, Dataset Loss: 0.3522\n",
            "Iteration 54300, Dataset Loss: 0.3391\n",
            "Iteration 54400, Dataset Loss: 0.3378\n",
            "Iteration 54500, Dataset Loss: 0.3457\n",
            "Iteration 54600, Dataset Loss: 0.3435\n",
            "Iteration 54700, Dataset Loss: 0.3637\n",
            "Iteration 54800, Dataset Loss: 0.3692\n",
            "Iteration 54900, Dataset Loss: 0.3654\n",
            "Iteration 55000, Dataset Loss: 0.3402\n",
            "Iteration 55100, Dataset Loss: 0.3405\n",
            "Iteration 55200, Dataset Loss: 0.3372\n",
            "Iteration 55300, Dataset Loss: 0.3506\n",
            "Iteration 55400, Dataset Loss: 0.3372\n",
            "Iteration 55500, Dataset Loss: 0.3443\n",
            "Iteration 55600, Dataset Loss: 0.3544\n",
            "Iteration 55700, Dataset Loss: 0.3415\n",
            "Iteration 55800, Dataset Loss: 0.3466\n",
            "Iteration 55900, Dataset Loss: 0.3427\n",
            "Iteration 56000, Dataset Loss: 0.3485\n",
            "Iteration 56100, Dataset Loss: 0.3498\n",
            "Iteration 56200, Dataset Loss: 0.3413\n",
            "Iteration 56300, Dataset Loss: 0.3378\n",
            "Iteration 56400, Dataset Loss: 0.3388\n",
            "Iteration 56500, Dataset Loss: 0.3466\n",
            "Iteration 56600, Dataset Loss: 0.3452\n",
            "Iteration 56700, Dataset Loss: 0.3412\n",
            "Iteration 56800, Dataset Loss: 0.3369\n",
            "Iteration 56900, Dataset Loss: 0.3361\n",
            "Iteration 57000, Dataset Loss: 0.3351\n",
            "Iteration 57100, Dataset Loss: 0.3427\n",
            "Iteration 57200, Dataset Loss: 0.3385\n",
            "Iteration 57300, Dataset Loss: 0.3379\n",
            "Iteration 57400, Dataset Loss: 0.3506\n",
            "Iteration 57500, Dataset Loss: 0.3341\n",
            "Iteration 57600, Dataset Loss: 0.3375\n",
            "Iteration 57700, Dataset Loss: 0.3361\n",
            "Iteration 57800, Dataset Loss: 0.3523\n",
            "Iteration 57900, Dataset Loss: 0.3373\n",
            "Iteration 58000, Dataset Loss: 0.3345\n",
            "Iteration 58100, Dataset Loss: 0.3559\n",
            "Iteration 58200, Dataset Loss: 0.3456\n",
            "Iteration 58300, Dataset Loss: 0.3435\n",
            "Iteration 58400, Dataset Loss: 0.3401\n",
            "Iteration 58500, Dataset Loss: 0.3341\n",
            "Iteration 58600, Dataset Loss: 0.3355\n",
            "Iteration 58700, Dataset Loss: 0.3350\n",
            "Iteration 58800, Dataset Loss: 0.3343\n",
            "Iteration 58900, Dataset Loss: 0.3418\n",
            "Iteration 59000, Dataset Loss: 0.3403\n",
            "Iteration 59100, Dataset Loss: 0.3353\n",
            "Iteration 59200, Dataset Loss: 0.3363\n",
            "Iteration 59300, Dataset Loss: 0.3496\n",
            "Iteration 59400, Dataset Loss: 0.3647\n",
            "Iteration 59500, Dataset Loss: 0.3422\n",
            "Iteration 59600, Dataset Loss: 0.3365\n",
            "Iteration 59700, Dataset Loss: 0.3388\n",
            "Iteration 59800, Dataset Loss: 0.3410\n",
            "Iteration 59900, Dataset Loss: 0.3506\n",
            "Iteration 60000, Dataset Loss: 0.3350\n",
            "Iteration 60100, Dataset Loss: 0.3331\n",
            "Iteration 60200, Dataset Loss: 0.3418\n",
            "Iteration 60300, Dataset Loss: 0.3378\n",
            "Iteration 60400, Dataset Loss: 0.3359\n",
            "Iteration 60500, Dataset Loss: 0.3415\n",
            "Iteration 60600, Dataset Loss: 0.3373\n",
            "Iteration 60700, Dataset Loss: 0.3435\n",
            "Iteration 60800, Dataset Loss: 0.3362\n",
            "Iteration 60900, Dataset Loss: 0.3401\n",
            "Iteration 61000, Dataset Loss: 0.3404\n",
            "Iteration 61100, Dataset Loss: 0.3697\n",
            "Iteration 61200, Dataset Loss: 0.3346\n",
            "Iteration 61300, Dataset Loss: 0.3360\n",
            "Iteration 61400, Dataset Loss: 0.3395\n",
            "Iteration 61500, Dataset Loss: 0.3345\n",
            "Iteration 61600, Dataset Loss: 0.3422\n",
            "Iteration 61700, Dataset Loss: 0.3398\n",
            "Iteration 61800, Dataset Loss: 0.3490\n",
            "Iteration 61900, Dataset Loss: 0.3366\n",
            "Iteration 62000, Dataset Loss: 0.3394\n",
            "Iteration 62100, Dataset Loss: 0.3574\n",
            "Iteration 62200, Dataset Loss: 0.3374\n",
            "Iteration 62300, Dataset Loss: 0.3403\n",
            "Iteration 62400, Dataset Loss: 0.3384\n",
            "Iteration 62500, Dataset Loss: 0.3442\n",
            "Iteration 62600, Dataset Loss: 0.3410\n",
            "Iteration 62700, Dataset Loss: 0.3363\n",
            "Iteration 62800, Dataset Loss: 0.3399\n",
            "Iteration 62900, Dataset Loss: 0.3451\n",
            "Iteration 63000, Dataset Loss: 0.3455\n",
            "Iteration 63100, Dataset Loss: 0.3432\n",
            "Iteration 63200, Dataset Loss: 0.3477\n",
            "Iteration 63300, Dataset Loss: 0.3354\n",
            "Iteration 63400, Dataset Loss: 0.3552\n",
            "Iteration 63500, Dataset Loss: 0.3708\n",
            "Iteration 63600, Dataset Loss: 0.3407\n",
            "Iteration 63700, Dataset Loss: 0.3392\n",
            "Iteration 63800, Dataset Loss: 0.3401\n",
            "Iteration 63900, Dataset Loss: 0.3506\n",
            "Iteration 64000, Dataset Loss: 0.3529\n",
            "Iteration 64100, Dataset Loss: 0.3483\n",
            "Iteration 64200, Dataset Loss: 0.3376\n",
            "Iteration 64300, Dataset Loss: 0.3400\n",
            "Iteration 64400, Dataset Loss: 0.3368\n",
            "Iteration 64500, Dataset Loss: 0.3348\n",
            "Iteration 64600, Dataset Loss: 0.3791\n",
            "Iteration 64700, Dataset Loss: 0.3348\n",
            "Iteration 64800, Dataset Loss: 0.3342\n",
            "Iteration 64900, Dataset Loss: 0.3383\n",
            "Iteration 65000, Dataset Loss: 0.3368\n",
            "Iteration 65100, Dataset Loss: 0.3370\n",
            "Iteration 65200, Dataset Loss: 0.3529\n",
            "Iteration 65300, Dataset Loss: 0.3410\n",
            "Iteration 65400, Dataset Loss: 0.3507\n",
            "Iteration 65500, Dataset Loss: 0.3356\n",
            "Iteration 65600, Dataset Loss: 0.3414\n",
            "Iteration 65700, Dataset Loss: 0.3408\n",
            "Iteration 65800, Dataset Loss: 0.3367\n",
            "Iteration 65900, Dataset Loss: 0.3438\n",
            "Iteration 66000, Dataset Loss: 0.3647\n",
            "Iteration 66100, Dataset Loss: 0.3656\n",
            "Iteration 66200, Dataset Loss: 0.3411\n",
            "Iteration 66300, Dataset Loss: 0.3388\n",
            "Iteration 66400, Dataset Loss: 0.3612\n",
            "Iteration 66500, Dataset Loss: 0.3347\n",
            "Iteration 66600, Dataset Loss: 0.3341\n",
            "Iteration 66700, Dataset Loss: 0.3355\n",
            "Iteration 66800, Dataset Loss: 0.3525\n",
            "Iteration 66900, Dataset Loss: 0.3435\n",
            "Iteration 67000, Dataset Loss: 0.3347\n",
            "Iteration 67100, Dataset Loss: 0.3525\n",
            "Iteration 67200, Dataset Loss: 0.3402\n",
            "Iteration 67300, Dataset Loss: 0.3347\n",
            "Iteration 67400, Dataset Loss: 0.3405\n",
            "Iteration 67500, Dataset Loss: 0.3409\n",
            "Iteration 67600, Dataset Loss: 0.3462\n",
            "Iteration 67700, Dataset Loss: 0.3407\n",
            "Iteration 67800, Dataset Loss: 0.3388\n",
            "Iteration 67900, Dataset Loss: 0.3343\n",
            "Iteration 68000, Dataset Loss: 0.3451\n",
            "Iteration 68100, Dataset Loss: 0.3345\n",
            "Iteration 68200, Dataset Loss: 0.3398\n",
            "Iteration 68300, Dataset Loss: 0.3367\n",
            "Iteration 68400, Dataset Loss: 0.3354\n",
            "Iteration 68500, Dataset Loss: 0.3380\n",
            "Iteration 68600, Dataset Loss: 0.3355\n",
            "Iteration 68700, Dataset Loss: 0.3428\n",
            "Iteration 68800, Dataset Loss: 0.3360\n",
            "Iteration 68900, Dataset Loss: 0.3357\n",
            "Iteration 69000, Dataset Loss: 0.3447\n",
            "Iteration 69100, Dataset Loss: 0.3417\n",
            "Iteration 69200, Dataset Loss: 0.3407\n",
            "Iteration 69300, Dataset Loss: 0.3360\n",
            "Iteration 69400, Dataset Loss: 0.3501\n",
            "Iteration 69500, Dataset Loss: 0.3351\n",
            "Iteration 69600, Dataset Loss: 0.3393\n",
            "Iteration 69700, Dataset Loss: 0.3381\n",
            "Iteration 69800, Dataset Loss: 0.3371\n",
            "Iteration 69900, Dataset Loss: 0.3335\n",
            "Iteration 70000, Dataset Loss: 0.3363\n",
            "Iteration 70100, Dataset Loss: 0.3350\n",
            "Iteration 70200, Dataset Loss: 0.3333\n",
            "Iteration 70300, Dataset Loss: 0.3456\n",
            "Iteration 70400, Dataset Loss: 0.3401\n",
            "Iteration 70500, Dataset Loss: 0.3347\n",
            "Iteration 70600, Dataset Loss: 0.3340\n",
            "Iteration 70700, Dataset Loss: 0.3346\n",
            "Iteration 70800, Dataset Loss: 0.3325\n",
            "Iteration 70900, Dataset Loss: 0.3343\n",
            "Iteration 71000, Dataset Loss: 0.3377\n",
            "Iteration 71100, Dataset Loss: 0.3469\n",
            "Iteration 71200, Dataset Loss: 0.3357\n",
            "Iteration 71300, Dataset Loss: 0.3315\n",
            "Iteration 71400, Dataset Loss: 0.3320\n",
            "Iteration 71500, Dataset Loss: 0.3340\n",
            "Iteration 71600, Dataset Loss: 0.3383\n",
            "Iteration 71700, Dataset Loss: 0.3425\n",
            "Iteration 71800, Dataset Loss: 0.3480\n",
            "Iteration 71900, Dataset Loss: 0.3405\n",
            "Iteration 72000, Dataset Loss: 0.3351\n",
            "Iteration 72100, Dataset Loss: 0.3331\n",
            "Iteration 72200, Dataset Loss: 0.3418\n",
            "Iteration 72300, Dataset Loss: 0.3595\n",
            "Iteration 72400, Dataset Loss: 0.3359\n",
            "Iteration 72500, Dataset Loss: 0.3485\n",
            "Iteration 72600, Dataset Loss: 0.3364\n",
            "Iteration 72700, Dataset Loss: 0.3345\n",
            "Iteration 72800, Dataset Loss: 0.3339\n",
            "Iteration 72900, Dataset Loss: 0.3365\n",
            "Iteration 73000, Dataset Loss: 0.3360\n",
            "Iteration 73100, Dataset Loss: 0.3548\n",
            "Iteration 73200, Dataset Loss: 0.3329\n",
            "Iteration 73300, Dataset Loss: 0.3365\n",
            "Iteration 73400, Dataset Loss: 0.3370\n",
            "Iteration 73500, Dataset Loss: 0.3497\n",
            "Iteration 73600, Dataset Loss: 0.3421\n",
            "Iteration 73700, Dataset Loss: 0.3319\n",
            "Iteration 73800, Dataset Loss: 0.3355\n",
            "Iteration 73900, Dataset Loss: 0.3323\n",
            "Iteration 74000, Dataset Loss: 0.3330\n",
            "Iteration 74100, Dataset Loss: 0.3309\n",
            "Iteration 74200, Dataset Loss: 0.3350\n",
            "Iteration 74300, Dataset Loss: 0.3341\n",
            "Iteration 74400, Dataset Loss: 0.3460\n",
            "Iteration 74500, Dataset Loss: 0.3384\n",
            "Iteration 74600, Dataset Loss: 0.3347\n",
            "Iteration 74700, Dataset Loss: 0.3403\n",
            "Iteration 74800, Dataset Loss: 0.3491\n",
            "Iteration 74900, Dataset Loss: 0.3321\n",
            "Iteration 75000, Dataset Loss: 0.3350\n",
            "Iteration 75100, Dataset Loss: 0.3331\n",
            "Iteration 75200, Dataset Loss: 0.3361\n",
            "Iteration 75300, Dataset Loss: 0.3371\n",
            "Iteration 75400, Dataset Loss: 0.3332\n",
            "Iteration 75500, Dataset Loss: 0.3323\n",
            "Iteration 75600, Dataset Loss: 0.3336\n",
            "Iteration 75700, Dataset Loss: 0.3353\n",
            "Iteration 75800, Dataset Loss: 0.3336\n",
            "Iteration 75900, Dataset Loss: 0.3344\n",
            "Iteration 76000, Dataset Loss: 0.3326\n",
            "Iteration 76100, Dataset Loss: 0.3335\n",
            "Iteration 76200, Dataset Loss: 0.3317\n",
            "Iteration 76300, Dataset Loss: 0.3332\n",
            "Iteration 76400, Dataset Loss: 0.3349\n",
            "Iteration 76500, Dataset Loss: 0.3326\n",
            "Iteration 76600, Dataset Loss: 0.3586\n",
            "Iteration 76700, Dataset Loss: 0.3417\n",
            "Iteration 76800, Dataset Loss: 0.3335\n",
            "Iteration 76900, Dataset Loss: 0.3341\n",
            "Iteration 77000, Dataset Loss: 0.3388\n",
            "Iteration 77100, Dataset Loss: 0.3376\n",
            "Iteration 77200, Dataset Loss: 0.3490\n",
            "Iteration 77300, Dataset Loss: 0.3681\n",
            "Iteration 77400, Dataset Loss: 0.3375\n",
            "Iteration 77500, Dataset Loss: 0.3386\n",
            "Iteration 77600, Dataset Loss: 0.3361\n",
            "Iteration 77700, Dataset Loss: 0.3384\n",
            "Iteration 77800, Dataset Loss: 0.3359\n",
            "Iteration 77900, Dataset Loss: 0.3345\n",
            "Iteration 78000, Dataset Loss: 0.3344\n",
            "Iteration 78100, Dataset Loss: 0.3390\n",
            "Iteration 78200, Dataset Loss: 0.3396\n",
            "Iteration 78300, Dataset Loss: 0.3410\n",
            "Iteration 78400, Dataset Loss: 0.3411\n",
            "Iteration 78500, Dataset Loss: 0.3353\n",
            "Iteration 78600, Dataset Loss: 0.3370\n",
            "Iteration 78700, Dataset Loss: 0.3387\n",
            "Iteration 78800, Dataset Loss: 0.3341\n",
            "Iteration 78900, Dataset Loss: 0.3331\n",
            "Iteration 79000, Dataset Loss: 0.3586\n",
            "Iteration 79100, Dataset Loss: 0.3341\n",
            "Iteration 79200, Dataset Loss: 0.3328\n",
            "Iteration 79300, Dataset Loss: 0.3452\n",
            "Iteration 79400, Dataset Loss: 0.3468\n",
            "Iteration 79500, Dataset Loss: 0.3657\n",
            "Iteration 79600, Dataset Loss: 0.3350\n",
            "Iteration 79700, Dataset Loss: 0.3329\n",
            "Iteration 79800, Dataset Loss: 0.3348\n",
            "Iteration 79900, Dataset Loss: 0.3366\n",
            "Iteration 80000, Dataset Loss: 0.3446\n",
            "Iteration 80100, Dataset Loss: 0.3524\n",
            "Iteration 80200, Dataset Loss: 0.3554\n",
            "Iteration 80300, Dataset Loss: 0.3506\n",
            "Iteration 80400, Dataset Loss: 0.3339\n",
            "Iteration 80500, Dataset Loss: 0.3369\n",
            "Iteration 80600, Dataset Loss: 0.3365\n",
            "Iteration 80700, Dataset Loss: 0.3319\n",
            "Iteration 80800, Dataset Loss: 0.3326\n",
            "Iteration 80900, Dataset Loss: 0.3385\n",
            "Iteration 81000, Dataset Loss: 0.3339\n",
            "Iteration 81100, Dataset Loss: 0.3382\n",
            "Iteration 81200, Dataset Loss: 0.3338\n",
            "Iteration 81300, Dataset Loss: 0.3349\n",
            "Iteration 81400, Dataset Loss: 0.3318\n",
            "Iteration 81500, Dataset Loss: 0.3345\n",
            "Iteration 81600, Dataset Loss: 0.3343\n",
            "Iteration 81700, Dataset Loss: 0.3354\n",
            "Iteration 81800, Dataset Loss: 0.3567\n",
            "Iteration 81900, Dataset Loss: 0.3340\n",
            "Iteration 82000, Dataset Loss: 0.3327\n",
            "Iteration 82100, Dataset Loss: 0.3339\n",
            "Iteration 82200, Dataset Loss: 0.3363\n",
            "Iteration 82300, Dataset Loss: 0.3324\n",
            "Iteration 82400, Dataset Loss: 0.3313\n",
            "Iteration 82500, Dataset Loss: 0.3322\n",
            "Iteration 82600, Dataset Loss: 0.3320\n",
            "Iteration 82700, Dataset Loss: 0.3358\n",
            "Iteration 82800, Dataset Loss: 0.3317\n",
            "Iteration 82900, Dataset Loss: 0.3384\n",
            "Iteration 83000, Dataset Loss: 0.3473\n",
            "Iteration 83100, Dataset Loss: 0.3323\n",
            "Iteration 83200, Dataset Loss: 0.3300\n",
            "Iteration 83300, Dataset Loss: 0.3299\n",
            "Iteration 83400, Dataset Loss: 0.3318\n",
            "Iteration 83500, Dataset Loss: 0.3336\n",
            "Iteration 83600, Dataset Loss: 0.3498\n",
            "Iteration 83700, Dataset Loss: 0.3365\n",
            "Iteration 83800, Dataset Loss: 0.3321\n",
            "Iteration 83900, Dataset Loss: 0.3343\n",
            "Iteration 84000, Dataset Loss: 0.3315\n",
            "Iteration 84100, Dataset Loss: 0.3318\n",
            "Iteration 84200, Dataset Loss: 0.3310\n",
            "Iteration 84300, Dataset Loss: 0.3402\n",
            "Iteration 84400, Dataset Loss: 0.3329\n",
            "Iteration 84500, Dataset Loss: 0.3438\n",
            "Iteration 84600, Dataset Loss: 0.3337\n",
            "Iteration 84700, Dataset Loss: 0.3374\n",
            "Iteration 84800, Dataset Loss: 0.3377\n",
            "Iteration 84900, Dataset Loss: 0.3472\n",
            "Iteration 85000, Dataset Loss: 0.3357\n",
            "Iteration 85100, Dataset Loss: 0.3328\n",
            "Iteration 85200, Dataset Loss: 0.3314\n",
            "Iteration 85300, Dataset Loss: 0.3358\n",
            "Iteration 85400, Dataset Loss: 0.3321\n",
            "Iteration 85500, Dataset Loss: 0.3335\n",
            "Iteration 85600, Dataset Loss: 0.3319\n",
            "Iteration 85700, Dataset Loss: 0.3316\n",
            "Iteration 85800, Dataset Loss: 0.3344\n",
            "Iteration 85900, Dataset Loss: 0.3359\n",
            "Iteration 86000, Dataset Loss: 0.3362\n",
            "Iteration 86100, Dataset Loss: 0.3349\n",
            "Iteration 86200, Dataset Loss: 0.3467\n",
            "Iteration 86300, Dataset Loss: 0.3473\n",
            "Iteration 86400, Dataset Loss: 0.3326\n",
            "Iteration 86500, Dataset Loss: 0.3361\n",
            "Iteration 86600, Dataset Loss: 0.3471\n",
            "Iteration 86700, Dataset Loss: 0.3315\n",
            "Iteration 86800, Dataset Loss: 0.3418\n",
            "Iteration 86900, Dataset Loss: 0.3342\n",
            "Iteration 87000, Dataset Loss: 0.3336\n",
            "Iteration 87100, Dataset Loss: 0.3342\n",
            "Iteration 87200, Dataset Loss: 0.3388\n",
            "Iteration 87300, Dataset Loss: 0.3328\n",
            "Iteration 87400, Dataset Loss: 0.3370\n",
            "Iteration 87500, Dataset Loss: 0.3589\n",
            "Iteration 87600, Dataset Loss: 0.3374\n",
            "Iteration 87700, Dataset Loss: 0.3389\n",
            "Iteration 87800, Dataset Loss: 0.3360\n",
            "Iteration 87900, Dataset Loss: 0.3366\n",
            "Iteration 88000, Dataset Loss: 0.3487\n",
            "Iteration 88100, Dataset Loss: 0.3356\n",
            "Iteration 88200, Dataset Loss: 0.3366\n",
            "Iteration 88300, Dataset Loss: 0.3369\n",
            "Iteration 88400, Dataset Loss: 0.3345\n",
            "Iteration 88500, Dataset Loss: 0.3340\n",
            "Iteration 88600, Dataset Loss: 0.3367\n",
            "Iteration 88700, Dataset Loss: 0.3403\n",
            "Iteration 88800, Dataset Loss: 0.3322\n",
            "Iteration 88900, Dataset Loss: 0.3450\n",
            "Iteration 89000, Dataset Loss: 0.3420\n",
            "Iteration 89100, Dataset Loss: 0.3327\n",
            "Iteration 89200, Dataset Loss: 0.3385\n",
            "Iteration 89300, Dataset Loss: 0.3422\n",
            "Iteration 89400, Dataset Loss: 0.3384\n",
            "Iteration 89500, Dataset Loss: 0.3330\n",
            "Iteration 89600, Dataset Loss: 0.3357\n",
            "Iteration 89700, Dataset Loss: 0.3403\n",
            "Iteration 89800, Dataset Loss: 0.3335\n",
            "Iteration 89900, Dataset Loss: 0.3361\n",
            "Iteration 90000, Dataset Loss: 0.3461\n",
            "Iteration 90100, Dataset Loss: 0.3353\n",
            "Iteration 90200, Dataset Loss: 0.3449\n",
            "Iteration 90300, Dataset Loss: 0.3350\n",
            "Iteration 90400, Dataset Loss: 0.3307\n",
            "Iteration 90500, Dataset Loss: 0.3397\n",
            "Iteration 90600, Dataset Loss: 0.3288\n",
            "Iteration 90700, Dataset Loss: 0.3344\n",
            "Iteration 90800, Dataset Loss: 0.3347\n",
            "Iteration 90900, Dataset Loss: 0.4031\n",
            "Iteration 91000, Dataset Loss: 0.3289\n",
            "Iteration 91100, Dataset Loss: 0.3315\n",
            "Iteration 91200, Dataset Loss: 0.3630\n",
            "Iteration 91300, Dataset Loss: 0.3311\n",
            "Iteration 91400, Dataset Loss: 0.3301\n",
            "Iteration 91500, Dataset Loss: 0.3300\n",
            "Iteration 91600, Dataset Loss: 0.3310\n",
            "Iteration 91700, Dataset Loss: 0.3285\n",
            "Iteration 91800, Dataset Loss: 0.3291\n",
            "Iteration 91900, Dataset Loss: 0.3347\n",
            "Iteration 92000, Dataset Loss: 0.3364\n",
            "Iteration 92100, Dataset Loss: 0.3320\n",
            "Iteration 92200, Dataset Loss: 0.3306\n",
            "Iteration 92300, Dataset Loss: 0.3322\n",
            "Iteration 92400, Dataset Loss: 0.3319\n",
            "Iteration 92500, Dataset Loss: 0.3408\n",
            "Iteration 92600, Dataset Loss: 0.3411\n",
            "Iteration 92700, Dataset Loss: 0.3317\n",
            "Iteration 92800, Dataset Loss: 0.3326\n",
            "Iteration 92900, Dataset Loss: 0.3325\n",
            "Iteration 93000, Dataset Loss: 0.3320\n",
            "Iteration 93100, Dataset Loss: 0.3332\n",
            "Iteration 93200, Dataset Loss: 0.3576\n",
            "Iteration 93300, Dataset Loss: 0.3314\n",
            "Iteration 93400, Dataset Loss: 0.3354\n",
            "Iteration 93500, Dataset Loss: 0.3314\n",
            "Iteration 93600, Dataset Loss: 0.3316\n",
            "Iteration 93700, Dataset Loss: 0.3376\n",
            "Iteration 93800, Dataset Loss: 0.3323\n",
            "Iteration 93900, Dataset Loss: 0.3337\n",
            "Iteration 94000, Dataset Loss: 0.3296\n",
            "Iteration 94100, Dataset Loss: 0.3319\n",
            "Iteration 94200, Dataset Loss: 0.3359\n",
            "Iteration 94300, Dataset Loss: 0.3291\n",
            "Iteration 94400, Dataset Loss: 0.3298\n",
            "Iteration 94500, Dataset Loss: 0.3308\n",
            "Iteration 94600, Dataset Loss: 0.3332\n",
            "Iteration 94700, Dataset Loss: 0.3392\n",
            "Iteration 94800, Dataset Loss: 0.3453\n",
            "Iteration 94900, Dataset Loss: 0.3309\n",
            "Iteration 95000, Dataset Loss: 0.3425\n",
            "Iteration 95100, Dataset Loss: 0.3308\n",
            "Iteration 95200, Dataset Loss: 0.3337\n",
            "Iteration 95300, Dataset Loss: 0.3309\n",
            "Iteration 95400, Dataset Loss: 0.3292\n",
            "Iteration 95500, Dataset Loss: 0.3301\n",
            "Iteration 95600, Dataset Loss: 0.3308\n",
            "Iteration 95700, Dataset Loss: 0.3332\n",
            "Iteration 95800, Dataset Loss: 0.3334\n",
            "Iteration 95900, Dataset Loss: 0.3680\n",
            "Iteration 96000, Dataset Loss: 0.3358\n",
            "Iteration 96100, Dataset Loss: 0.3315\n",
            "Iteration 96200, Dataset Loss: 0.3327\n",
            "Iteration 96300, Dataset Loss: 0.3354\n",
            "Iteration 96400, Dataset Loss: 0.3327\n",
            "Iteration 96500, Dataset Loss: 0.3315\n",
            "Iteration 96600, Dataset Loss: 0.3523\n",
            "Iteration 96700, Dataset Loss: 0.3308\n",
            "Iteration 96800, Dataset Loss: 0.3334\n",
            "Iteration 96900, Dataset Loss: 0.3300\n",
            "Iteration 97000, Dataset Loss: 0.3308\n",
            "Iteration 97100, Dataset Loss: 0.3342\n",
            "Iteration 97200, Dataset Loss: 0.3359\n",
            "Iteration 97300, Dataset Loss: 0.3305\n",
            "Iteration 97400, Dataset Loss: 0.3305\n",
            "Iteration 97500, Dataset Loss: 0.3341\n",
            "Iteration 97600, Dataset Loss: 0.3687\n",
            "Iteration 97700, Dataset Loss: 0.3346\n",
            "Iteration 97800, Dataset Loss: 0.3322\n",
            "Iteration 97900, Dataset Loss: 0.3367\n",
            "Iteration 98000, Dataset Loss: 0.3303\n",
            "Iteration 98100, Dataset Loss: 0.3306\n",
            "Iteration 98200, Dataset Loss: 0.3352\n",
            "Iteration 98300, Dataset Loss: 0.3677\n",
            "Iteration 98400, Dataset Loss: 0.3351\n",
            "Iteration 98500, Dataset Loss: 0.3389\n",
            "Iteration 98600, Dataset Loss: 0.3355\n",
            "Iteration 98700, Dataset Loss: 0.3515\n",
            "Iteration 98800, Dataset Loss: 0.3360\n",
            "Iteration 98900, Dataset Loss: 0.3387\n",
            "Iteration 99000, Dataset Loss: 0.3317\n",
            "Iteration 99100, Dataset Loss: 0.3332\n",
            "Iteration 99200, Dataset Loss: 0.3357\n",
            "Iteration 99300, Dataset Loss: 0.3390\n",
            "Iteration 99400, Dataset Loss: 0.3420\n",
            "Iteration 99500, Dataset Loss: 0.3327\n",
            "Iteration 99600, Dataset Loss: 0.3349\n",
            "Iteration 99700, Dataset Loss: 0.3395\n",
            "Iteration 99800, Dataset Loss: 0.3353\n",
            "Iteration 99900, Dataset Loss: 0.3395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_arr = np.array(X_test_scaled)\n",
        "y_arr = np.array(y_test).reshape(1, -1)\n",
        "z1_test = np.dot(w1s, X_arr.T) + b1s\n",
        "a1_test = np.maximum(0, z1_test)\n",
        "z2_test = np.dot(w2s, a1_test) + b2s\n",
        "a2_test = np.maximum(0, z2_test)\n",
        "z3_test = np.dot(w3s, a2_test) + b3s\n",
        "z3_test = z3_test.astype(np.float64)\n",
        "y_hat_test = 1 / (1 + np.exp(-np.clip(z3_test, -500, 500)))\n",
        "\n",
        "y_pred = (y_hat_test >= 0.5).astype(int)\n",
        "accuracy_sc = np.mean(y_pred == y_arr) * 100\n",
        "print(\"Case1: Scaled data Accuracy-\", accuracy_sc)"
      ],
      "metadata": {
        "id": "_zap1WN-amtV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730e7372-eaf9-4396-ccb7-4321433b9829"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case1: Scaled data Accuracy- 83.8523432221608\n"
          ]
        }
      ]
    }
  ]
}